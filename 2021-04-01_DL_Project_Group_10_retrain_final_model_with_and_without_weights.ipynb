{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "determined-remark",
   "metadata": {},
   "source": [
    "# Deep Learning Project - Traffic Signs Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "authentic-cyprus",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "prescription-conspiracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_hist_to_excel(filename):\n",
    "    df = pd.DataFrame(history.history)\n",
    "    df.to_excel(filename + '.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vietnamese-attention",
   "metadata": {},
   "source": [
    "## Overview of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "civic-alberta",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 43 different classes within the training data!\n"
     ]
    }
   ],
   "source": [
    "#setting the training directory (the training images can be found there, already sorted by class into folders)\n",
    "#base_training_dir = \"/Users/henriquevaz/NOVA IMS/YEAR 1/SPRING SEMESTER/DL/Project/my_notebooks/Data/Training/Final_Training/Images/\"\n",
    "base_training_dir = \"/Users/philippmetzger/Documents/GitHub/Deep_Learning_Project_Group_10/Data/GTSRB_Final_Training_Images/GTSRB/Final_Training/Images/\"\n",
    "#base_training_dir = \"/Users/franz/Desktop/DL Project/Train/Final_Training/Images\"\n",
    "\n",
    "#setting the directory where the selected training and validation images will be stored in\n",
    "#created_dir = \"/Users/henriquevaz/NOVA IMS/YEAR 1/SPRING SEMESTER/DL/Project/my_notebooks/Data/Selected\"\n",
    "created_dir = \"/Users/philippmetzger/Documents/GitHub/Deep_Learning_Project_Group_10/Data/Selected\"\n",
    "#created_dir = \"/Users/franz/Desktop/DL Project/Selected\"\n",
    "\n",
    "#storing all the folder names that belong to the respective classes\n",
    "all_classes = sorted(i for i in os.listdir(base_training_dir) if i.startswith(\"0\"))\n",
    "\n",
    "print(\"There are\", len(all_classes), \"different classes within the training data!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "passing-copper",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the number of images within each class of the training data\n",
    "amount_per_class = {}\n",
    "\n",
    "for i in range(len(all_classes)):\n",
    "    directory = base_training_dir + \"/\" + all_classes[i]\n",
    "    amount_per_class[i] = len(sorted(i for i in os.listdir(directory) if i.startswith(\"0\")))\n",
    "\n",
    "amount_per_class_df = pd.DataFrame.from_dict(amount_per_class, orient='index').rename(columns={0:\"amount\"})\n",
    "amount_per_class_df.index.name = 'class'\n",
    "\n",
    "#remove the \"#\" of the following line to display the number of images within each class\n",
    "#amount_per_class_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "smart-notification",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKAAAAH9CAYAAAAtcQQyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABBHUlEQVR4nO3de5x1ZVk//s8leC45iBIC+aDiKc0Tipbao3gASUkzy0whNfx5KC0r8ZCglmJapt9Ks/BUJuYZxQOIEWqioiKiiKA+KshBEs8HBO/fH2sNbIaZeWbPrPXM7OH9fr32a/a+19rXvvba+56955r7vle11gIAAAAAY7nGWicAAAAAwMamAAUAAADAqBSgAAAAABiVAhQAAAAAo1KAAgAAAGBUClAAAAAAjEoBCgCYWlWdWFVtrfMYUlXtXVXvqKrzq6pV1Xe2sv+mfr/XbZsMWa+qaktVbVnrPABgPdt+rRMAgKuriQLO15PcqrX2kwX22ZLkpkmu2Vq7dBumd7VSVdsleWeSWyT59yTnJLnK6wEAwMooQAHA2vvlJE9LcuQa53F1tleS2yb519baocu8z7lJbpPku6NlBQCwQZiCBwBr6+Ik305yWFXtstbJXI3dpP/5zeXeobX2s9baF1tr542UEwDAhqEABQBr60dJXpBkhySHL+cOVbW5X3voiEW2X2U9mqo6pL/PIVV1/6r6cFX9oKq+VVWvraod+/3uVFXvqaqL++3HVNWmJXK5dlX9dVV9tap+WlVfrqrDq+pai+x/66p6XVV9o6ouqaoLquo/q+pWC+z7uj7nm1XVH1fVaVX146o6cZnH6S5V9baqurDP7WtV9c9Vtdu8/VqS/+lvHt4/5qLHd+J+C64BNZH3XlX1lKr6QlX9pH9dnlVV1e/3O1X1iar6YZ/jP1bVdRd4nN+qqv+oqi/1+/6wqj5VVX9SVQt+l6uqW/bP/eJ+//+tqgMn3wcL3GePPoev9Mfr//rX/64L7PuLVfVXVXV6VX2vqr7fv/Zvrqq7LHXcJmKc2Oeynt9De1TVK6rqrP5+3+5fs79axn13qKq/qKoPVdU5fa7f6o/pPRa5z72q6t39/j+tbj2yk6vq8Hn77VpVL62qM/vX9zv99ddV1c2W89wAYFszBQ8A1t4/JXlKkidU1Staa2eN+FgPSfKbSd6T5FVJfi3JIUk2VdUzk5yQ5MNJjkpy+yQPTnKzqvrV1trPF4j3X0numuStSX6W5KAkRyTZp6oe0lq7fKHyqto/yduTXDPJu5OcnWSPJA9LcmBV3ae19ukFHuPlSe6V5Ngk701y2daeZFX9ZpK3Jak+t68luUuSJyY5qKru2Vr7ar/785JsSnJwukLUiX37iVmdlybZnO65Hpfu2P9NkmtV1bfTTbl8Z7rjff8kT06yXZ/jpCOT/DzJx9NN+9shyX3THZe7Jnn05M5Vdesk/5tkp3TH7LQkN0vyjnTH7yqq6s59jjsn+UC612mXJL+V5CNV9dDW2nv7fSvJ+9O9dz6W5N+SXJrutbxP/3w+tdyDlPX7Hton3bHYOclJ/eNeL91UzSPSFY6Xcpt0r/dJ/eNenG667UOSHFBVD26tvX/eczs2yfeSHJPutd65j/OkdO/TVNX1knw0yc2THN8fh0q3VtxB6Y7jV7b2/ABgm2utubi4uLi4uKzBJUlLck5//eH97bfP22dL3779RNvmvu2IReJuSbJlXtsh/X0uTfIbE+3XSPdHbEs3FfBR8+53VL/toHntJ/btX0qy00T7ddIVJVqSR0+075TuD/CLktx2XqzbJflBkk/Pa39dH+fcJHtNcVx/Icn/pSsy3Gvetmf0MY+b177kMV3kcTb193ndInlvSbL7RPuO/fP/YZJvJbnNxLZrJ/lCkp8mufG8eDdf4LGvkeT1/ePsO2/bCX37E+e1H9C3tySHTLRvn66Q85PJ90a/7Sb98T8vybX7ttv3Md6xSF47zW9f5Pit5/fQtZJ8tb/v7y+wfY9l9Lkdkuyy0H3TTfU8Y1772/rHu8MC99ll4vqD+/1etkjev7jc5+ni4uLi4rItL6bgAcA60Fp7a7o/uh9aVfcc8aHe1Fqbm26W1o1q+vf+5umttTfO2/8N/c87LhLvBa21iyfi/STJM/ubj53Y7zHpCjCHt9a+MBmgtXZ6kn9Ncqequu0Cj/G37YrRSstxULqRI29urX143ra/S1csuH9V/fIUMVfiBa21c+dutNa+k25ky/WSvLK1dsbEtp8meXO6AsJtJoO01r48P3D/ur28v/nAufaq2jPd6Kizk/zLvPu8L8kHF8jzwHSjaf7f5Hujv883k/xtkl9Kst+8+/14obwm3w/LtB7fQw9OV2A8prX2n/M3ttbO2VqA1tp3W2sXLXLftya59SLvwYWO61XiLLLfJa21728tNwBYC6bgAcD68fR0U6demuTuIz3GKQu0zS28vdC0qbkCyh6LxPufBdo+km700Z0m2ubWvLlDLby20i37n7dJNxJo0icWeezF3Ln/+aH5G1prl1bVSemKC3dK8vUpY09jkGNdVTdM8hdJHpRuKt31591v94nrd+x/fqwtPGXyI0nuN69t7rW56SKvzd79z9ukm772hSSnJnlkVd00ybv6uKe01i5Z4P5bsx7fQ3P9731T3u9KqurXkzw1Xe43TldgnLR7rngPvjHdVMKPV9Wbk/x3ko8uUOz6n3TvlcP6qZPvTTcl79TW2lanFgLAWlGAAoB1orX2sap6a5KHV9XvttbePMLDfHeBtkuXse2ai8S7YH5DX+S5KN0f3HNu2P/8o63k9wsLtJ2/lfvMt0P/c7Gz08217zhl3Gmt+lhXtzj8J5Psla6I8oZ0UyUvTZf/U9NN35sz99yv8ros0T732vzOIveZ8wtJ0lq7rKrum+S56aaOvrjf/v2qen2SZ7bWfrCVWEvmtA7eQzv2P89daqelVNVD0410+km6aa5fTjf98ufppnz+RiZeu9ba2/u1y56ebuTXE/o4n0p3TI/v9/teVd093ZpQD8kVI+Auqqp/TvLXrbWfrTRvABiLAhQArC/PTDeF7EVV9Y5F9pkb2bLY5/iOSb4zbFqL2jXzRhFV1fbpFrD+3kTzXMHlDq2106Z8jLb1Xa5k7rF+aZHtu83bbz17fLri0/Naa0dMbujPpPbUefvPHfNdF4m3UPvccTiotXbMcpLqp8z9aZI/rapbpCumPCHdYvo7Zt7C6FuxHt9D3+l/7r7UTlvxgiSXJNlncrplklTVv6Q7ZlfSWjs2ybFVdf0k+6Y7YcATk7ynqu40N/WwHxX1uH5B+Numm3b55HRFwWsk2epZ+gBgW7MGFACsI621s5P8c7qiwx8vstvcejl7zt/QFwN2mN8+oqv8EZ3knunO5vaZibaT+5/3Gj2jKx538/wNfWFjLoeFzpa23tyi//m2BbYtdOxP7X/eo6oW+p630Ppiq3ptWmtnt9aO6vP5QboC6jTW43to7rEOWEWMWyT5wgLFp2tk4dfhcq21H7bWPtRa+7MkL0w3de8qubTO51tr/y/dmRST7syFALDuKEABwPrz/HQjMJ6dhacTfTHdyJCDquryKUpVdd0kr9gWCU74q6raaSKH6yR5UX/ztRP7vTbdczq8qu42P0hVXaOqNg+U0zvTTVN7ZD9VadLT0hX3PthaG3P9p6Fs6X9unmysqjvlioW6L9c/pxPTFT+eMO8+++eq6z8l3RpOX07y5Kp60EJJVNU9qup6/fW9qupmC+y2U7opZVdZHHsr1uN76N3pjv1DquqRCzzWYmuiTdqSZO+qusnE/SrJEelGLc2Pee++QDrf3Ki1H/X7/UpVLTSS7Ur7AcB6YwoeAKwzrbVvV9UL0519bKHtP6uql6ebZvOZfqre9ulGQHwzVyx0vS2ckeTz/dpVP0s3+uXmSY7NFWfXS2vt/6rq4UnekeTkqjohyefTTY3aM90izTdMcp3VJtRa+0FVPTbJW5L8T1W9Jd0Ur7skeUC69YCesESI9eQN6RYg/4equk+Ss9ItCv6bSd6e5HcXuM+T0y1K/c99Qem0dIuX/3a6YtNBuWIa59z76WFJPpBu+tf/phtJ9aN0r81d+/vv1rfdIcnbq+qT6V7/bya5UR/3mrliTajlWo/voUuq6neSHJfkP6vqCelGRV0n3SLn+2Xr36NfluRV6fro2/rn9uvpik/vTnemvUmvSLJ7VX00XfHqknTv2fsm+VqSo/v97p/kJVX1sSRfSnJhuoXr517Xl6zsWQPAuBSgAGB9ekWSJ6U7W9tCDk9XDPijJIemK6ocnW50xfwzgI3pEekKYY9KcpN0izYfkeTI1tqV1t1prZ1QVb+a5M/TLZx8r3R/ZH8z3RnrFppmtiKttXf1ZyB7Vv9YO6Q7Rq9K8oLW2rYs0q1Ya+2bVXWvJEemm7b1wHQj4J6U5INZoADVWvtCvz7UC9MVL+6brgj10HTFk4Ny5bWV0lo7rarukOTP0hW3/jBdMeO8dNPgDk9yUb/7KX0+v5Fk/3Qjn76V7sx+r2itTXvmuPX6Hjqlqu6Y5LB0099+Lcn3k5ydbq2lrd3/X6rqp+lG3R2cbmTYh9Md29/OVQtQL0z3Gu2TbqTaz9MVTl+Y5B/6dbeSrlD4y0nune61vEG61+n4JH/fWvvfFT1hABhZzftcBwBgg6qqNyb5/SS3bq2duca5nJjkN1prtZZ5AADbhjWgAAA2kH4tpKucAbCq9ks3YuoLa118AgCufkzBAwDYWK6V5BtV9d/pputdmuRX0q0ddEm6NaIAALYpBSgAgI3lZ+nWurpvkn2TXC/d+k1vSbeu0mfWMDcA4GrKGlAAAAAAjMoaUAAAAACM6mo5BW///fdv73//+9c6DQAAAICNZNGz214tR0BddNFFa50CAAAAwNXG1bIABQAAAMC2owAFAAAAwKgUoAAAAAAYlQIUAAAAAKNSgAIAAABgVApQAAAAAIxKAQoAAACAUSlAAQAAADAqBSgAAAAARqUABQAAAMCoFKAAAAAAGJUCFAAAAACjUoACAAAAYFQKUAAAAACMSgEKAAAAgFEpQAEAAAAwKgUoAAAAAEalAAUAAADAqBSgAAAAABjV9mudAFdvmw47drBYW448cLBYAAAAwHCMgAIAAABgVApQAAAAAIxKAQoAAACAUSlAAQAAADAqi5CzJIuEAwAAAKtlBBQAAAAAo1KAAgAAAGBUClAAAAAAjEoBCgAAAIBRKUABAAAAMCoFKAAAAABGpQAFAAAAwKgUoAAAAAAYlQIUAAAAAKNSgAIAAABgVNuvdQIAkCSbDjt2sFhbjjxwsFgAAMDqGQEFAAAAwKgUoAAAAAAYlQIUAAAAAKNSgAIAAABgVApQAAAAAIxKAQoAAACAUSlAAQAAADAqBSgAAAAARqUABQAAAMCoFKAAAAAAGNX2a50AALNj02HHDhZry5EHDhYLAABY34yAAgAAAGBUClAAAAAAjEoBCgAAAIBRKUABAAAAMCoFKAAAAABG5Sx4AAAAMKOcpZhZYQQUAAAAAKNSgAIAAABgVApQAAAAAIxKAQoAAACAUSlAAQAAADAqBSgAAAAARqUABQAAAMCoFKAAAAAAGNWaFaCqas+q+u+q+kJVfb6qntq371xVx1fVWf3Pnfr2qqpXVNXZVXVaVd15ItbB/f5nVdXBa/WcAAAAALiqtRwBdWmSp7fWbpvk7kmeXFW3TXJYkhNaa3snOaG/nSQHJNm7vxya5JVJV7BKcniSfZPcLcnhc0UrAAAAANbe9mv1wK2185Kc11//flWdkWT3JAcl2dzv9vokJyZ5Rt/+htZaS3JyVe1YVbv1+x7fWvt2klTV8Un2T/KmbfZkAJZp02HHDhZry5EHDhYLAABgTOtiDaiq2pTkTkk+nmTXvjiVJOcn2bW/vnuSb0zc7Zy+bbF2AAAAANaBNRsBNaeqfiHJ25I8rbX2vaq6fFtrrVVVG+hxDk03dS+77rprTjzxxCHCbnhPv/2lg8Va6JiPHR/Wm1l/z4+Z/6wfGwCAteA7FOvJ5s2bF922pgWoqrpmuuLTG1trb++bL6iq3Vpr5/VT7C7s289NsufE3ffo287NFVP25tpPnP9YrbVXJ3l1kuyzzz5tqYPCFQ4ZcrrQozZv8/iw3sz6e37M/Gf92AAArAXfoZgVa3kWvEpyVJIzWmt/P7HpmCRzZ7I7OMm7Jtof058N7+5JvttP1ftAkgdU1U794uMP6NsAAAAAWAfWcgTUryd5dJLPVdWpfduzkhyZ5L+q6nFJvpbkEf229yZ5UJKzk/woyR8mSWvt21X1giSf7Pd7/tyC5DAmi0kDAADA8qzlWfA+kqQW2bzfAvu3JE9eJNZrkrxmuOwAAAAAGMq6OAseAAAAABuXAhQAAAAAo1KAAgAAAGBUClAAAAAAjEoBCgAAAIBRKUABAAAAMCoFKAAAAABGpQAFAAAAwKgUoAAAAAAYlQIUAAAAAKNSgAIAAABgVApQAAAAAIxKAQoAAACAUSlAAQAAADAqBSgAAAAARqUABQAAAMCoFKAAAAAAGJUCFAAAAACjUoACAAAAYFQKUAAAAACMavu1TgBY2KbDjh0s1pYjDxwsFgAAAEzLCCgAAAAARqUABQAAAMCoFKAAAAAAGJUCFAAAAACjUoACAAAAYFQKUAAAAACMSgEKAAAAgFEpQAEAAAAwKgUoAAAAAEalAAUAAADAqBSgAAAAABiVAhQAAAAAo1KAAgAAAGBUClAAAAAAjEoBCgAAAIBRKUABAAAAMCoFKAAAAABGpQAFAAAAwKgUoAAAAAAYlQIUAAAAAKNSgAIAAABgVApQAAAAAIxKAQoAAACAUSlAAQAAADAqBSgAAAAARqUABQAAAMCoFKAAAAAAGJUCFAAAAACjUoACAAAAYFQKUAAAAACMSgEKAAAAgFEpQAEAAAAwKgUoAAAAAEalAAUAAADAqBSgAAAAABiVAhQAAAAAo1KAAgAAAGBUClAAAAAAjEoBCgAAAIBRKUABAAAAMCoFKAAAAABGpQAFAAAAwKgUoAAAAAAYlQIUAAAAAKNadgGqqm5RVfvPa9u3qt5dVR+tqkOHTw8AAACAWbf9FPu+OMnOSd6fJFW1S5L3JfmFJD9O8sqqurC19s6hkwQAAABgdk0zBW+fJB+cuP3IJDdIcuckN0ry8SRPHS41AAAAADaCaQpQN0ryzYnb+yf5aGvt9NbaJUmOTnLbIZMDAAAAYPZNU4D6YZIdk6SqtktyzyQnTWz/cboRUQAAAABwuWkKUJ9P8piqumGSP0q39tPxE9tvmuRbA+YGAAAAwAYwzSLkL0nyriQX9rc/k+TDE9sfkOTTA+UFAAAAwAax7AJUa+3YqrpvkoOSfDfJP7bWWpL0o6LOSfKGUbIEAAAAYGZNMwIqrbWTcuV1n+ba/y/Jw4ZKCgAAAICNY6oCVJJU1fWT3CPJrkk+2Fq7YPCsAAAAANgwplmEPFX1xCTnJjku3XS7X+nbb1xVP6mqPxo+RQAAAABm2bILUFX120n+Kcl/J3l8kprb1lq7MMn7k/zWwPkBAAAAMOOmGQH1F0n+u7X20HRnw5vvlCS3GyQrAAAAADaMaQpQt0/yjiW2n5fkxqtLBwAAAICNZpoC1GVb2f8mSX64unQAAAAA2GimKUB9NskDF9pQVddI8jtJPjlEUgAAAABsHNMUoP4xyQFV9YIkO8/dv6puleQt6c6I94qB8wMAAABgxm2/3B1ba2+uqtsneXaSZ/bN7093NrxKckRr7X3DpwgAAADALJtmBFRaa89Jsk+Slyd5X5Lj0o2Multr7fnTxKqq11TVhVV1+kTbEVV1blWd2l8eNLHtmVV1dlWdWVUPnGjfv287u6oOmyYHAAAAAMa37BFQc1prn07y6QEe+3XpildvmNf+stbaSycbquq2SX4v3TS/myT5YFXdst/8T0nun+ScJJ+sqmNaa18YID8AAAAABjB1AWoorbWTqmrTMnc/KMnRrbWfJvlqVZ2d5G79trNba19Jkqo6ut9XAQoAAABgnVh2AaqqXrOVXVqSHyf5epLjW2ufWWFOT6mqxyQ5JcnTW2sXJ9k9yckT+5zTtyXJN+a177vCxwUAAABgBNVaW96OVT9PV2RKukXHJ81vb0mOTvKY1tplS8TclOQ9rbXb9bd3TXJRf/8XJNmttfbYqvrHJCe31v6j3++odGtQJcn+rbXH9+2PTrJva+0pCzzWoUkOTZJdd931LkcfffSynvfV3efO/e5gsW6/+w7bPP6YHBtWYtZf1zHzn/VjA8wWv3OAjcLvM9aTzZs3z68XXW6aKXg3SnfWuy8n+bskZ/btt07y9CSbkjwiyS5J/jLdmk2nJ3nRch+gtXbB3PWq+tck7+lvnptkz4ld9+jbskT7/NivTvLqJNlnn33a5s2bl5vW1dohhx07WKwtj9q8zeOPybFhJWb9dR0z/1k/NsBs8TsH2Cj8PmNWTHMWvJcmuaC19nuttU+21r7XXz7RWvvddCOXjmitfaq//dEkfzBNMlW128TNh6YrYCXJMUl+r6quXVV7Jdk7ySeSfDLJ3lW1V1VdK13R65hpHhMAAACAcU0zAurBSZ67xPZjkzx/4vYx825fSVW9KcnmJLtU1TlJDk+yuarumG4K3pYkT0iS1trnq+q/0i0ufmmSJ89N7auqpyT5QJLtkrymtfb5KZ4TAAAAACObpgB1nSQ3WWL7Hv0+c36Yrli0oNbaIxdoPmqJ/f8myd8s0P7eJO9dIi8AAAAA1tA0Baj/TfLHVfWe1trkGelSVfdI8pR+nzm3z5XPUAcwEzYNNI9+y5EHDhIHAABg1k1TgPrzJB9O8tGq+kSuWIT8VknuluQH/T6pquskuW+Sdw6WKQAAAAAzadkFqNbaaVV1lyQvTHJAkn37TT9M8rYkz2mtfanf9yfpzo4HAAAAwNXcNCOg0lo7O8kjquoaSW7UN3+rtfbzwTMDAAAAYEOYqgA1py84XTBwLgAAAABsQFMXoKpqu3TT63ZKco3521trJw2QFwAAAAAbxFQFqKp6RpLDktxgid22W1VGwMwb6ixyiTPJAQAAbARXGcG0mKp6XJIXJTk1yXOSVJJ/SPKSJN9OckqSxw6eIQAAAAAzbdkFqCRPTHJya+0+SV7dtx3bWjssya8m2RSjnwAAAACYZ5oC1G2SvKW/3vqf2yVJa+28dEWppw6XGgAAAAAbwTQFqMuS/LC/PvfzhhPbtyTZe4CcAAAAANhAplmE/OtJ9kqS1tpPq+obSe6V5Oh++13TrQUF64KFsDcury0AAMBsmaYAdVKSA5M8s7/9liRPq6rrphtJ9QdJXjNsegAAAADMumkKUC9P8tmqum5r7cdJDk9yyyQH99uPS3LYwPkBAAAAMOOWXYBqrZ2Z5MyJ2z9M8pCq2iHJZa21H4yQHwAAAAAzbpoRUAtqrX13iEQAAAAA2JimLkBV1fWSbEp3Bryav721dtLq0wIAAABgo1h2Aaqqrp/kZUkek+SaC+2SpCXZbpjUAAAAANgIphkB9aokj0ryjiQfTnLxKBkBAAAAsKFMU4A6KMlRrbU/GisZAAAAADaea0yx78+SfHKsRAAAAADYmKYpQH0oyb5jJQIAAADAxjRNAerpSfarqqdW1UKLkAMAAADAVSx7DajW2ter6llJ3pDkJVV1XpLLrrpbu/mQCQIAAAAw25ZdgKqqQ5IcleSSJGfGWfAAAAAAWIZpzoL37CSnJnlga+2icdIBAAAAYKOZZg2o3ZMcpfgEAAAAwDSmKUCdmWTnsRIBAAAAYGOaZgreC5O8vKpe11o7Z6yEAFi5TYcdO1isLUceOFgsAADg6m2aAtRtkpyb5IyqekeSr2bhs+C9YKjkAAAAAJh90xSgjpi4/geL7NOSKEABAAAAcLlpClB7jZYFAAAAABvWsgtQrbWvjZkIAAAAABvTNGfBAwAAAICpLToCqqqem25Np79prf28v701FiEHAAAA4EqWmoJ3RLoC1IuTXJIrL0K+GIuQAwAAAHAlSxWg9kqS1tolk7cBAAAAYBqLFqDmLzpuEXIAAAAAVsIi5AAAAACMSgEKAAAAgFEpQAEAAAAwKgUoAAAAAEalAAUAAADAqBYtQFXVh6pqv4nbj6mqTdskKwAAAAA2jKVGQG1OsuvE7dcm+bVRswEAAABgw1mqAHVekr0mbtfIuQAAAACwAW2/xLYTkjynqvZJcnHfdmhV3W+J+7TW2uMGyw4AAACAmbdUAepPk7Qk90vyS/31e/eXxbQkClAAAAAAXG7RKXittf9rrR3cWtu9tbZduil4f9Bau8YSl+22XeoAAAAAzIKl1oCa73lJThsrEQAAAAA2pqWm4F1Ja+15k7erape+/aKhkwIANo5Nhx07WKwtRx44WCwAZofPEph904yASlXdpKpeX1XfSXJBkguq6uKqel1V7T5KhgAAAADMtGWPgKqqX05ycroFyU9N8vl+022TPCbJ/avq7q21bwydJAAAAACza9kFqCQvSLJTkt9srb13ckNVHZDk7f0+hwyWHQAAAAAzb5opeA9I8s/zi09J0lp7X5JXJtl/qMQAAAAA2BimKUDtlOSsJbaflWTHVWUDAAAAwIYzTQHqnCSbl9h+734fAAAAALjcNAWotyT5nap6UVXtMNdYVTeoqhcmeUSSNw+dIAAAAACzbdpFyO+V5BlJ/ryqvtm33yTJdkk+muSvh00PAAAAgFm37BFQrbUfpZuC94QkxyX5YX/5QJJDk9yntfbjEXIEAAAAYIZNMwIqrbVLk/xrfwEAAACArZpmDSgAAAAAmJoCFAAAAACjUoACAAAAYFQKUAAAAACMSgEKAAAAgFEt6yx4VXXtJPsmOa+1dta4KQEA29Kmw44dLNaWIw8cLBYAABvHckdAXZbkhCQHjJgLAAAAABvQsgpQrbVLk5yfpMZNBwAAAICNZpo1oN6S5BFVZd0oAAAAAJZtWWtA9f4tyX2SHF9V/5DkrCQ/mr9Ta+3rw6QGAAAAwEYwTQHq9CQt3TS8zUvst91qEgIAAABgY5mmAPX8dAUoAAAAAFi2ZRegWmtHjJgHAAAAABuUBcUBAAAAGNVUBaiq+sWqem5VfaSqzqqqe/Ttu/Tttx4nTQAAAABm1bKn4FXVjZJ8JMnNkpzd/7xukrTWLqqqg5PsmOTPhk8TAAAAgFk1zSLkf53kl5Lsm+TrSS6ct/1dSfYbKC8AAAAANohppuD9ZpJ/bq19OgufDe8rSfYcJCsAAAAANoxpClC7pJt6t5ifJ7nO6tIBAAAAYKOZpgB1fpKbL7H9Tumm5gEAAADA5aYpQL03yeOqarf5G6pq3ySPSbcOFAAAAABcbpoC1POSXJrkM0lelG4dqIOr6k1JTkryzSQvHjxDAAAAAGbasgtQrbXzk9w9yceTPDZJJXl0kkckOS7JvVpr315uvKp6TVVdWFWnT7TtXFXHV9VZ/c+d+vaqqldU1dlVdVpV3XniPgf3+59VVQcv9/EBAAAA2DamGQGV1to3WmsHJdk5yb7pClI3aq09uLV2zpSP/bok+89rOyzJCa21vZOc0N9OkgOS7N1fDk3yyqQrWCU5vM/lbkkOnytaAQAAALA+TFWAmtNa+15r7ZOttU9MM+ppXoyTksy/70FJXt9ff32S35pof0PrnJxkx34tqgcmOb619u3W2sVJjs9Vi1oAAAAArKHtp71DVd0tyUOT3Kxv+kqSd7bWPj5APru21s7rr5+fZNf++u5JvjGx3zl922LtAAAAAKwT1Vpb3o5V2yV5dZJD0q3/NKkleUOSx7fWLlv2g1dtSvKe1trt+tvfaa3tOLH94tbaTlX1niRHttY+0refkOQZSTYnuU5r7a/79r9K8uPW2ksXeKxD003fy6677nqXo48+erlpXq197tzvDhbr9rvvsE3jz3Lu2yL+mGb92AwVf5ZzX4v4s/yen3Wz/L6BlfK+hNmizy7OsWE92bx58/x60eWmGQH1nCR/mOSdSf42yRf69l9J8pdJHpNkS7qz5a3UBVW1W2vtvH6K3YV9+7lJ9pzYb4++7dx0RajJ9hMXCtxae3W6Alr22Weftnnz5oV2Y55DDjt2sFhbHrV5m8af5dy3RfwxzfqxGSr+LOe+FvFn+T0/62b5fQMr5X0Js0WfXZxjw6yYZg2ox6Zbb+lhrbWT+3Wgvtda+1hr7aFJPtTvsxrHJJk7k93BSd410f6Y/mx4d0/y3X6q3geSPKCqduoXH39A3wYAAADAOjFNAerG6QpBi3lnv8+yVNWbknwsya2q6pyqelySI5Pcv6rOSnK//naSvDfdWlNnJ/nXJE9Kkn4B9Bck+WR/ef5KF0UHAAAAYBzTTMH7UpJfWmL7bv0+y9Jae+Qim/ZbYN+W5MmLxHlNktcs93EBAAAA2LamGQH1oiRPrqo7zN9QVXdKNyrphUMlBgAAAMDGsOgIqKp67gLNX01ySlUdl+SLfdttktw/yWeT3HLwDAEAAACYaUtNwTtiiW0H9JdJd05yp3RrMgEAAABAkqULUHttsywAAAAA2LAWLUC11r62LRMBAAAAYGOaZhFyAAAAAJjaUlPwrqKqbprk0CR7J7lhkpq3S2ut7TdQbgAAAABsAMsuQFXVQ5K8Jck1k3wvycVjJQUAAADAxjHNCKgXJ/lGkoe21j43Uj4AAAAAbDDTrAG1KckrFJ8AAAAAmMY0BaivJrn2WIkAAAAAsDFNU4D6hySPr6rrj5QLAAAAABvQsteAaq29uqpukOTzVfX6JFuSXLbAfm8YLj0AAAAAZt00Z8HbNcnDkvxykr9aZLeWRAEKAAAAgMtNcxa8VyW5a5KXJflwkotHyQgAAACADWWaAtR+SV7eWvvzsZIBAAAAYOOZZhHynyY5e6xEAAAAANiYpilAHZvk/mMlAgAAAMDGNE0B6s+S7FlVr6iqm1dVjZUUAAAAABvHNGtAXZTuLHd3SfLkJFmgBtVaa9PEBAAAAGCDm6ZY9IZ0BSgAAAAAWLZlF6Baa4eMmAcAAAAAG9Q0a0ABAAAAwNSWPQKqqn55Ofu11r6+8nQAAAAA2GimWQNqS5a3BtR2K0sFAAAAgI1omgLU83PVAtT2SW6e5KAkn0vyvoHyAgAAAGCDmGYR8iMW21ZVN0vysSSnDJATAAAAABvIIIuQt9a+kuRfkjxviHgAAAAAbBxDngXv3CS3HTAeAAAAABvAkAWo30py8YDxAAAAANgAlr0GVFU9d5FNOye5b5LbJfnbIZICAAAAYOOY5ix4Ryyx7fwkz0ny4lVlAwAAAMCGM00Baq8F2lqSb7fWfjBQPgAAAABsMMsuQLXWvjZmIgAAAABsTEMuQg4AAAAAVzHNFLxU1T2SPCXJ3klumKTm7dJaazcfKDcAGMymw44dLNaWIw8cLBYAs8NnCcDKTXMWvMckeW2SnyX5UpKvj5UUAAAAABvHNCOgnp3kzCT3a619c6R8AAAAANhgplkD6qZJXqn4BAAAAMA0pilAnZPk2mMlAgAAAMDGNE0B6lVJHlVV242VDAAAAAAbzzRrQH0qyW8n+URV/VOSrya5bP5OrbWTBsoNAAAAgA1gmgLUCRPX/y1Jm7e9+jYjpAAAAAC43DQFqD8cLQsAAAAANqxlF6Baa68fMxEAAAAANqZpFiEHAAAAgKkpQAEAAAAwKgUoAAAAAEalAAUAAADAqBSgAAAAABiVAhQAAAAAo1KAAgAAAGBU2691AgAAAIxr02HHDhZry5EHDhYLuPowAgoAAACAUSlAAQAAADAqBSgAAAAARqUABQAAAMCoFKAAAAAAGJUCFAAAAACjUoACAAAAYFQKUAAAAACMSgEKAAAAgFEpQAEAAAAwqu3XOgEA2Ag2HXbsYLG2HHngYLEAAGA9MAIKAAAAgFEpQAEAAAAwKgUoAAAAAEalAAUAAADAqCxCDgAAA3JSAgC4KiOgAAAAABiVAhQAAAAAo1KAAgAAAGBUClAAAAAAjEoBCgAAAIBRKUABAAAAMCoFKAAAAABGpQAFAAAAwKgUoAAAAAAYlQIUAAAAAKPafq0TAAAA1o9Nhx07WKwtRx44WCwAZpsRUAAAAACMSgEKAAAAgFEpQAEAAAAwqnVZgKqqLVX1uao6tapO6dt2rqrjq+qs/udOfXtV1Suq6uyqOq2q7ry22QMAAAAwaV0WoHr3aa3dsbW2T3/7sCQntNb2TnJCfztJDkiyd385NMkrt3mmAAAAACxqls6Cd1CSzf311yc5Mckz+vY3tNZakpOraseq2q21dt6aZAkAcDXgTGkAwDTW6wioluS4qvpUVR3at+06UVQ6P8mu/fXdk3xj4r7n9G0AAAAArAPVDRxaX6pq99bauVV14yTHJ/njJMe01nac2Ofi1tpOVfWeJEe21j7St5+Q5BmttVPmxTw03RS97Lrrrnc5+uijt9GzmW2fO/e7g8W6/e47bNP4s5z7tog/plk/NkPFn+Xc1yL+LOe+LeKPybFhJWb9dZ3l32djm/X8xzTLx2aWc09mP/8xOTasJ5s3b67Ftq3LAtSkqjoiyQ+S/FGSza2186pqtyQnttZuVVX/0l9/U7//mXP7LRZzn332aaeccspim5kw9vD6MePPcu7bIv6YZv3YDBV/lnNfi/iznPu2iD8mx4aVmPXXdZZ/n41t1vMf0ywfm1nOPZn9/Mfk2LDOLFqAWndT8Krq+lX1i3PXkzwgyelJjklycL/bwUne1V8/Jslj+rPh3T3Jd63/BAAAALB+rMdFyHdN8o6qSrr8/rO19v6q+mSS/6qqxyX5WpJH9Pu/N8mDkpyd5EdJ/nDbpwwAAADAYtZdAaq19pUkd1ig/f+S7LdAe0vy5G2QGgAAAAArsO6m4AEAAACwsShAAQAAADAqBSgAAAAARqUABQAAAMCo1t0i5AAAACux6bBjB4u15cgDB4sFgBFQAAAAAIxMAQoAAACAUSlAAQAAADAqBSgAAAAARmURcrgaskAnzBZ9FoD1zmcVsDVGQAEAAAAwKgUoAAAAAEalAAUAAADAqBSgAAAAABiVAhQAAAAAo3IWPACADcpZqQCWZ6jfl35XwuKMgAIAAABgVApQAAAAAIxKAQoAAACAUSlAAQAAADAqBSgAAAAARuUseAAAi3AWOQAYj8/ZqxcjoAAAAAAYlQIUAAAAAKNSgAIAAABgVApQAAAAAIzKIuQAAGvE4qsAwNWFEVAAAAAAjEoBCgAAAIBRKUABAAAAMCoFKAAAAABGpQAFAAAAwKicBQ8AAABYkDO2MhQjoAAAAAAYlQIUAAAAAKNSgAIAAABgVApQAAAAAIzKIuQAAKw7Fr3duLy2AFdPRkABAAAAMCoFKAAAAABGpQAFAAAAwKgUoAAAAAAYlQIUAAAAAKNyFjwAAJghziK3cXltYVhj9yl9djpGQAEAAAAwKgUoAAAAAEalAAUAAADAqBSgAAAAABiVRchnnEXPALi681kIwHrmcwo6RkABAAAAMCoFKAAAAABGpQAFAAAAwKgUoAAAAAAYlQIUAAAAAKNSgAIAAABgVApQAAAAAIxKAQoAAACAUSlAAQAAADAqBSgAAAAARqUABQAAAMCoFKAAAAAAGJUCFAAAAACjUoACAAAAYFQKUAAAAACMSgEKAAAAgFEpQAEAAAAwKgUoAAAAAEalAAUAAADAqBSgAAAAABiVAhQAAAAAo1KAAgAAAGBUClAAAAAAjEoBCgAAAIBRKUABAAAAMCoFKAAAAABGpQAFAAAAwKgUoAAAAAAYlQIUAAAAAKNSgAIAAABgVApQAAAAAIxKAQoAAACAUSlAAQAAADAqBSgAAAAARrVhClBVtX9VnVlVZ1fVYWudDwAAAACdDVGAqqrtkvxTkgOS3DbJI6vqtmubFQAAAADJBilAJblbkrNba19prV2S5OgkB61xTgAAAABk4xSgdk/yjYnb5/RtAAAAAKyxaq2tdQ6rVlUPT7J/a+3x/e1HJ9m3tfaUiX0OTXJof/NWSc7c5omurV2SXDSDsWc9/iznPuvxZzn3sePPcu6zHn+Wcx87/iznPnb8Wc591uPPcu5jx5/l3MeOP8u5z3r8Wc597PiznPusxx879/Xmotba/gtt2H5bZzKSc5PsOXF7j77tcq21Vyd59bZMaj2pqlNaa/vMWuxZjz/Luc96/FnOfez4s5z7rMef5dzHjj/LuY8df5Zzn/X4s5z72PFnOfex489y7rMef5ZzHzv+LOc+6/HHzn2WbJQpeJ9MsndV7VVV10rye0mOWeOcAAAAAMgGGQHVWru0qp6S5ANJtkvymtba59c4LQAAAACyQQpQSdJae2+S9651HuvYmNMPx57aOMvxZzn3WY8/y7mPHX+Wc5/1+LOc+9jxZzn3sePPcu6zHn+Wcx87/iznPnb8Wc591uPPcu5jx5/l3Gc9/tV2KaD5NsQi5AAAAACsXxtlDSgAAAAA1ikFqA2uqvavqjOr6uyqOmzg2K+pqgur6vQh407E37Oq/ruqvlBVn6+qpw4Y+zpV9Ymq+mwf+3lDxZ73ONtV1Weq6j0jxN5SVZ+rqlOr6pSBY+9YVW+tqi9W1RlVdY8BY9+qz3nu8r2qetpQ8fvH+NP+dT29qt5UVdcZMPZT+7ifHyrvhfpSVe1cVcdX1Vn9z50GjP07ff4/r6pVnZFjkfgv6d87p1XVO6pqx4Hjv6CPfWpVHVdVNxkq9sS2p1dVq6pdBs79iKo6d+L9/6Ah4/ftf9wf/89X1d8OmPubJ/LeUlWnDpl7Vd2xqk6e+51WVXcbOP4dqupj/e/Nd1fVDVYYe8HPpgH77GLxB+m3S8Rfdb9dIvZQfXbJ7wWr7bdL5L/qfrtU7gP12cVyH6TfLhF/1f12idhD9dkFv/NVd/Kij1f3HfnN1Z3IaMj4T+ljr/azZLH4b6zuO/7p1f3Ou+aAsY/q206r7vvgLwyZ+8T2V1TVD1YSeyv5v66qvjrx3r/jgLGrqv6mqr5U3XfkPxk49w9P5P3NqnrnwPH3q6pP9/E/UlW3GDj+ffv4p1fV66tqxUv+1Ly/o4bqs0vEH6TPLhJ71f11w2ituWzQS7oF2b+c5GZJrpXks0luO2D8eye5c5LTR8p/tyR37q//YpIvDZV/kkryC/31ayb5eJK7j/Ac/izJfyZ5zwixtyTZZaRj//okj++vXyvJjiM9znZJzk9y0wFj7p7kq0mu29/+rySHDBT7dklOT3K9dGvofTDJLQaIe5W+lORvkxzWXz8syYsHjH2bJLdKcmKSfUbI/QFJtu+vv3iluS8R/wYT1/8kyauGit2375nupBZfW00fWyT3I5L8+UDvx4Xi36d/X167v33jIY/NxPa/S/LcgXM/LskB/fUHJTlx4PifTPIb/fXHJnnBCmMv+Nk0YJ9dLP4g/XaJ+Kvut0vEHqrPLvq9YIh+u0T+q+63S8Qeqs9u9TvTavrtEvmvut8uEXuoPrvgd7503w9+r29/VZInDhz/Tkk2ZZXf15aI/6B+WyV500ryXyL2ZJ/9+/S/24aK39/eJ8m/J/nBCMfmdUkevtK4W4n9h0nekOQa/baV9tmt/i2S5G1JHjNw/l9Kcpu+/UlJXjdg/F9L8o0kt+zbn5/kcat4Da70d9RQfXaJ+IP02UVir7q/bpSLEVAb292SnN1a+0pr7ZIkRyc5aKjgrbWTknx7qHgLxD+vtfbp/vr3k5yRrrgwROzWWpv7j8s1+8ugC6JV1R5JDkzyb0PGHVtV7ZDuj7ejkqS1dklr7TsjPdx+Sb7cWvvawHG3T3Ld/r8u10vyzYHi3ibJx1trP2qtXZrkf5I8bLVBF+lLB6UrBKb/+VtDxW6tndFaO3Ml8ZYZ/7j++CTJyUn2GDj+9yZuXj8r7LtL/A57WZK/XGncZcQfxCLxn5jkyNbaT/t9LhwwdpLuv79JHpHuC9SKLBK/JZkb4bBDVtFvF4l/yyQn9dePT/LbK4y92GfTUH12wfhD9dsl4q+63y4Re6g+u9T3glX325G/dywWe6g+u2Tuq+23S8Rfdb9dIvZQfXax73z3TfLWvn01fXbB+K21z7TWtqwk5jLjv7ff1pJ8Iivrs4vF/l5y+fvmull5n10wflVtl+Ql6frsio35fX6J2E9M8vzW2s/7/VbaZ5fMvboRf/dN8s6B4w/yWbtI/MuSXNJa+1LfvuJ+O//vqP69OEifXSh+kgzVZxeJver+ulEoQG1su6erQs85JwN9kdrWqmpTuqr0xweMuV11Q9EvTHJ8a22w2L1/SPfB+vOB485pSY6rqk9V1aEDxt0rybeSvLYfOvpvVXX9AeNP+r2s4o/YhbTWzk3y0iRfT3Jeku+21o4bKPzpSe5VVTesquul+2/GngPFnm/X1tp5/fXzk+w60uOM7bFJ3jd00H74+zeSPCrJcweMe1CSc1trnx0q5gKe0k9reE2tcJrWEm6Z7j368ar6n6q668Dxk+ReSS5orZ01cNynJXlJ/7q+NMkzB47/+VzxT5jfyQB9d95n0+B9dozPvmXGX3W/nR976D47GX+MfrvAsRms386LPXifXeR1Hazfzov/tAzYb+fFHqzPzv/Ol26GwHcmiq6r+o489nfKpeL3U3keneT9Q8auqtem+1126yT/b+Dcn5LkmInfmSu2xLH5m77Pvqyqrj1g7Jsn+d3qppy+r6r2HiH3pCuunDCvgD9E/McneW9VnZPufXPkUPHTFVa2ryumiT88K++3/5Ar/x11wwzYZxeIP6RFY6+2v24EClCse9XNO39bkqet5pfwfK21y1prd0xXgb5bVd1uqNhV9ZtJLmytfWqomAu4Z2vtzkkOSPLkqrr3QHG3Tzd15ZWttTsl+WG66SSD6udtPyTJWwaOu1O6L6x7JblJkutX1R8MEbu1dka6qSnHpfvgODXdf3tG1f+3ZNARettCVT07yaVJ3jh07Nbas1tre/axnzJEzL6o+KwMWNBawCvTfXm9Y7oC6d8NHH/7JDunG2b/F0n+q/+v4ZAemYELx70nJvnT/nX90/SjMAf02CRPqqpPpZvmc8lqgi312TREnx3rs29r8YfotwvFHrLPTsbvcx203y6Q/2D9doHYg/bZJd43g/TbBeIP1m8XiD1Yn53/nS9dUWUwY36nXEb8f05yUmvtw0PGbq39YbrvUWck+d0Bc793uoLiiotaW4l/u3SF0FsnuWu6/vWMAWNfO8lPWmv7JPnXJK8ZOPc5q+6zi8T/0yQPaq3tkeS16aZYDhI/ya+k++fyy6rqE0m+nxV8Tx7776gx4y8j9qr660agALWxnZsrV5336NtmRl8lfluSN7bW3j7GY7Ruetl/J9l/wLC/nuQhVbUl3dTH+1bVfwwYf26kz9zQ33ek+8U/hHOSnDPxX5i3pitIDe2AJJ9urV0wcNz7Jflqa+1brbWfJXl7ujnpg2itHdVau0tr7d5JLk43l34MF1TVbknS/1zREO+1UlWHJPnNJI/q/xgfyxuzwuHdC7h5usLlZ/u+u0eST1fVLw0UP621C/ovbD9P98V1qH4755wkb+9HeX8i3X/fVrWQ5qTqprU+LMmbh4o54eB0/TXpCtODHpvW2hdbaw9ord0l3Zf6L6801iKfTYP12bE/+xaLP0S/XUbuq+qzC8QftN8ulP9Q/XaRYzNYn13idR2k3y4Sf5B+u8hxH6zPzpn4znePJDvWFQskD/IdeaTvlIvGr6rDk9wo3Xozg8bu2y5L9z121Z+zE/Hvk+QWSc7u++z1qursAePv37ppna11U1tfm1V+nsw7Nufkivf8O5L86mpiLxA/1S2Afbckx6429rz4ByS5w8R3/DdngO/I8479x1pr92qt3S3dFNqVfE++yt9RSV6e4frsmH+nLRp7yP46yxSgNrZPJtm7ujMGXCtdRfqYNc5p2fr/AB6V5IzW2oqr84vEvlH1Z/ipqusmuX+SLw4Vv7X2zNbaHq21TemO+4daa4OMwkmSqrp+Vf3i3PV0i8cOcjbC1tr5Sb5RVbfqm/ZL8oUhYs8z1iiKrye5e1Vdr38P7Zfuv3eDqKob9z9/Od0X+v8cKvY8x6T7Yp/+57tGepzBVdX+6YYeP6S19qMR4k8Odz8oA/Xd1trnWms3bq1t6vvuOekWxj1/iPjJ5YWJOQ/NQP12wjvTfblPVd0y3UkELhow/v2SfLG1ds6AMed8M8lv9Nfvm2TQKX4TffcaSZ6TbgHTlcRZ7LNpkD475mffUvGH6LdLxB6kzy4Uf8h+u0T+q+63S7yu78wAfXYr75tV99sl4q+63y5x3Ifqswt95zsj3R/MD+93W02fHfU75WLxq+rxSR6Y5JF9cXSo2GdWf2a0/rV5SFbeZxeK/6nW2i9N9NkftdZWeia2xY7N3D8DKt1UtpX02cVe13em77Pp3vsr+kfkVt43D0+3ePVPVhJ7ifhnJNmh/12TibbB8p/ot9dON/Js6n67yN9Rj8pAfXbMv9MWiz1Ef90w2jpYCd1lvEu6NWq+lO6/Rs8eOPab0g1F/1m6L3wrPsvBIvHvmW4Kw2nppjqdmm7I6BCxfzXJZ/rYp2cVZ3NaxmNtzsBnwUt3ZsPP9pfPj/Da3jHJKf3xeWeSnQaOf/0k/5dkh5GO+fPSfYifnu4MK9ceMPaH0xXkPptkv4FiXqUvpZvrfkK6L/MfTLLzgLEf2l//aZILknxg4NzPTrf+3Fy/XdEZr5aI/7b+tT0tybvTLXI8SOx527dkdWcuWij3f0/yuT73Y5LsNnD8ayX5j/74fDrJfYc8NunOLPT/jfSev2eST/V96+NJ7jJw/Kem+zz8Uro1L2qFsRf8bBqwzy4Wf5B+u0T8VffbJWIP1We3+r1gNf12ifxX3W+XiD1Un1302GSAfrtE/qvut0vEHqrPLvidL913qU/07/23ZIXfFZaI/yfp+uyl6Qp1/zZw/EvTfb+fO2ZTf5ddKHa6AQof7d/zp6cbtXiDIXOft89qzoK32LH50ET+/5H+bG0Dxd4x3cikzyX5WLoRRYMem3RnO91/pcdlK/k/tM/9s/3j3Gzg+C9JV9Q6M9102hU/hz7e5lxxJrlB+uwS8Qfps4vEXnV/3SiX6g8IAAAAAIzCFDwAAAAARqUABQAAAMCoFKAAAAAAGJUCFAAAAACjUoACAAAAYFQKUAAA21hVHVJVrao2r3UuAADbggIUAAAAAKNSgAIAAABgVApQAAAAAIxKAQoAYEBVda2q+suqOrWqflRV362qU6rqKVu53y9W1V9X1cer6qKq+mlVnV1VR1bV9ebte42qelpVnVZV36+q71XVmVV1VFVdc2K/X6uq91XV+VX1k6o6t6reW1V3H+v5AwAsZPu1TgAAYKOoqmsl+UCSzUmOS/IfSX6S5PZJHpbkH5e4++5JHp/kbUn+M8mlSX4jyV8muVOSB07s++wkz0/y7iSvSnJZkr2SPCTJtZP8rKpuleT4JOcneXmSC5LsmuSeSe6Q5ORVPl0AgGVTgAIAGM7T0hWfXtRae9bkhqra2sjzryTZs7X2s4m2f6qqFyR5TlXdrbX2ib79oUnOaK09ZF6MwyauPzDJ9ZI8cuJ+AABrwhQ8AIDhPCrJxelGJ11Ja+3nS92xtXbJXPGpqravqp2qapckH+x32Xdi9+8m2b2q7rlEyO/2Pw+qquss9wkAAIxBAQoAYDh7J/lia+0nK7lzVT2pqk5L8tMk307yrSQn9pt3mtj1Wemm9n24X9fpjVX1+/0UwDlHpytePSvJt6vqQ1X1jKq66UpyAwBYDQUoAIB1oKr+LMk/JTkvyROSHJjk/kkO6Xe5/Htba+1jSW6e5OFJ3pHkjknemOTUqtq53+enrbX7pxs59aJ060Q9P8kXq+qh4z8jAIArWAMKAGA4X0py66q6dmvtp1Pe99FJtiQ5YHK6XlXtv9DOrbUfpFuw/G39fk9KV8B6XJKXTOz3iSSf6PfZM8lnkvx1usIVAMA2YQQUAMBw3phuqtxz5m+oqtrKfS9L0pJcvl9VbZ8rLyw+177LAvf/dP9z5yX2OSfdtL6dt5ILAMCgjIACABjOy5M8ON1Z6+6a5Lh0azX9SpJbJbnfEvd9a7qpcu+rqrcnuUGS30/yswX2PaOqTk7y8STfTLJbkkOTXJJu7af0OTwgyXuSfDVdYevBSW6d5G9X8RwBAKamAAUAMJDW2iV90efp6YpHL0xXgDoryWu3cveXpCsSPS5dIev8JG/u7/eFefv+XZIHJfmTJDskuTDJyUle1Fr7bL/PO9MVph6RZNckP+7z+KMkR630OQIArES11tY6BwAAAAA2MGtAAQAAADAqBSgAAAAARqUABQAAAMCoFKAAAAAAGJUCFAAAAACjUoACAAAAYFQKUAAAAACMSgEKAAAAgFEpQAEAAAAwKgUoAAAAAEb1/wMl0l9yfDdS1AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#displaying the number of images per class visually\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20,8)\n",
    "fig, ax = plt.subplots()\n",
    "plt.bar(amount_per_class_df.index, amount_per_class_df.amount)\n",
    "plt.title(\"Number of images per class\", fontsize=20)\n",
    "plt.xlabel('class', fontsize=18)\n",
    "plt.ylabel('number of images', fontsize=18)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.xticks(amount_per_class_df.index)\n",
    "plt.grid(axis=\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contained-certification",
   "metadata": {},
   "source": [
    "As it can be seen in the bar chart, the dataset is highly unbalanced. Some classes have over 2000 instances, while others only have 210."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "exempt-married",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>class</th>\n",
       "      <th>0</th>\n",
       "      <th>37</th>\n",
       "      <th>19</th>\n",
       "      <th>32</th>\n",
       "      <th>27</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>24</th>\n",
       "      <th>29</th>\n",
       "      <th>39</th>\n",
       "      <th>21</th>\n",
       "      <th>40</th>\n",
       "      <th>20</th>\n",
       "      <th>36</th>\n",
       "      <th>22</th>\n",
       "      <th>6</th>\n",
       "      <th>16</th>\n",
       "      <th>34</th>\n",
       "      <th>30</th>\n",
       "      <th>23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>amount</th>\n",
       "      <td>210</td>\n",
       "      <td>210</td>\n",
       "      <td>210</td>\n",
       "      <td>240</td>\n",
       "      <td>240</td>\n",
       "      <td>240</td>\n",
       "      <td>240</td>\n",
       "      <td>270</td>\n",
       "      <td>270</td>\n",
       "      <td>300</td>\n",
       "      <td>330</td>\n",
       "      <td>360</td>\n",
       "      <td>360</td>\n",
       "      <td>390</td>\n",
       "      <td>390</td>\n",
       "      <td>420</td>\n",
       "      <td>420</td>\n",
       "      <td>420</td>\n",
       "      <td>450</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "class    0    37   19   32   27   41   42   24   29   39   21   40   20   36  \\\n",
       "amount  210  210  210  240  240  240  240  270  270  300  330  360  360  390   \n",
       "\n",
       "class    22   6    16   34   30   23  \n",
       "amount  390  420  420  420  450  510  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#displaying the 20 classes with the fewest images\n",
    "amount_per_class_df.sort_values(\"amount\").head(20).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "favorite-romance",
   "metadata": {},
   "source": [
    "Within each class, there are several groups of images, that belong together (these are basically all images of the very same traffic sign, that just differ in that they were made as a series while approaching the actual sign). These series of images shouldn't be splitted later when the data is split into training and validation sets, so some precautions might be useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "closed-romania",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a series whose number doesn't match the others in class 00033 , with the prefix 00019 !\n",
      "It only contains 29 images.\n",
      "All the other series of images contain exactly 30 images!\n"
     ]
    }
   ],
   "source": [
    "#checking the size(=amount of images) of these series and whether they are all having the same size\n",
    "\n",
    "#running a for loop over all classes\n",
    "for i in range(len(all_classes)):\n",
    "    directory = base_training_dir + \"/\" + all_classes[i]\n",
    "    \n",
    "    #get the names of all images within a class\n",
    "    list_of_images = sorted(i for i in os.listdir(directory) if i.startswith(\"0\"))\n",
    "\n",
    "    image_series = []\n",
    "    \n",
    "    #store all the prefixes of the images (which correspond to the series they belong to)\n",
    "    for element in list_of_images:\n",
    "        image_series.append(element.split(\"_\")[0])\n",
    "    \n",
    "    #count the frequency of each prefix, which equals the size of each respective series\n",
    "    image_counts = pd.Series(image_series).value_counts().sort_index()\n",
    "\n",
    "    for element in image_counts.values.tolist():\n",
    "        if element != image_counts.values.tolist()[0]:\n",
    "            #this line will show if there is a series that contains not the same number of images than the others\n",
    "            print(\"There is a series whose number doesn't match the others in class\", all_classes[i], \", with the prefix\", image_counts.sort_values().index[0], \"!\\nIt only contains\", element, \"images.\")\n",
    "            \n",
    "\n",
    "#apart from only one series, all others consist of exactly 30 images\n",
    "print(\"All the other series of images contain exactly\", image_counts.values.tolist()[0], \"images!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enormous-council",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infinite-attraction",
   "metadata": {},
   "source": [
    "After running the upper part once, the notebook can be started from here from now on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dental-decrease",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#this cell is optional and the notebook should be runned from here once the upper part has been executed once\n",
    "\n",
    "import os, shutil\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "beginning-dover",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dir = new_train_dir\n",
    "#validation_dir = new_val_dir\n",
    "\n",
    "train_dir = '/Users/philippmetzger/Documents/GitHub/Deep_Learning_Project_Group_10/Data/GTSRB_Final_Training_Images/GTSRB/Final_Training/Images'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "individual-cliff",
   "metadata": {},
   "source": [
    "##### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "improving-tribute",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 39209 images belonging to 43 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "#test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(100,100),\n",
    "    batch_size=20,\n",
    "    class_mode=\"categorical\",\n",
    "    color_mode=\"grayscale\"\n",
    "    )\n",
    "\n",
    "\n",
    "#validation_generator = test_datagen.flow_from_directory(\n",
    "#    validation_dir,\n",
    "#    target_size=(100,100),\n",
    "#    batch_size=20,\n",
    "#    class_mode=\"categorical\",\n",
    "#    color_mode=\"grayscale\"\n",
    "#    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "continuing-threat",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=np.concatenate([train_generator.next()[0] for i in range(train_generator.__len__())])\n",
    "#x_val=np.concatenate([validation_generator.next()[0] for i in range(validation_generator.__len__())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "turkish-mozambique",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
    "#test_datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
    "\n",
    "train_datagen.fit(x_train)\n",
    "#test_datagen.fit(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "happy-amplifier",
   "metadata": {},
   "source": [
    "##### Re-Creating the generators with the normalized image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "particular-fireplace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 39209 images belonging to 43 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(100,100),\n",
    "    batch_size=20,\n",
    "    class_mode=\"categorical\",\n",
    "    color_mode=\"grayscale\"\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "#validation_generator = test_datagen.flow_from_directory(\n",
    "#    validation_dir,\n",
    "#    target_size=(100,100),\n",
    "#    batch_size=20,\n",
    "#    class_mode=\"categorical\",\n",
    "#    color_mode=\"grayscale\"\n",
    "#    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "peripheral-exercise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data batch shape: (20, 100, 100, 1)\n",
      "labels batch shape: (20, 43)\n"
     ]
    }
   ],
   "source": [
    "sys.modules['Image'] = Image\n",
    "\n",
    "for data_batch, labels_batch in train_generator:\n",
    "    print('data batch shape:', data_batch.shape)\n",
    "    print('labels batch shape:', labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plastic-dominican",
   "metadata": {},
   "source": [
    "## Define the final model without weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "declared-concrete",
   "metadata": {},
   "source": [
    "Note that in this one the filter size is changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "widespread-anthony",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 98, 98, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 49, 49, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 49, 49, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 45, 45, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 128)       401536    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               4194816   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 43)                22059     \n",
      "=================================================================\n",
      "Total params: 4,669,995\n",
      "Trainable params: 4,669,995\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2), strides=2))\n",
    "model.add(layers.Dropout(0.1))\n",
    "model.add(layers.Conv2D(64, (5, 5), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2), strides=2))\n",
    "model.add(layers.Dropout(0.15))\n",
    "model.add(layers.Conv2D(128, (7, 7), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2), strides=2 ))\n",
    "model.add(layers.Dropout(0.15))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dropout(0.4))\n",
    "model.add(layers.Dense (43, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "central-inquiry",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "#compilation\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.RMSprop(lr=1e-4), metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twenty-portrait",
   "metadata": {},
   "source": [
    "## Train the final model without weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "simplified-gross",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [], 'acc': []}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = ['loss', 'acc']\n",
    "history_all = {}\n",
    "for item in items:\n",
    "    history_all[item] = []\n",
    "history_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dependent-january",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1961/1961 [==============================] - 486s 248ms/step - loss: 6.6950 - acc: 0.1224\n",
      "INFO:tensorflow:Assets written to: model_final_without_weights_after_epoch_1/assets\n",
      "1961/1961 [==============================] - 483s 246ms/step - loss: 0.8926 - acc: 0.7753\n",
      "INFO:tensorflow:Assets written to: model_final_without_weights_after_epoch_2/assets\n",
      "1961/1961 [==============================] - 469s 239ms/step - loss: 0.3015 - acc: 0.9290\n",
      "INFO:tensorflow:Assets written to: model_final_without_weights_after_epoch_3/assets\n",
      "1961/1961 [==============================] - 471s 240ms/step - loss: 0.1685 - acc: 0.9620\n",
      "INFO:tensorflow:Assets written to: model_final_without_weights_after_epoch_4/assets\n",
      "1961/1961 [==============================] - 479s 244ms/step - loss: 0.1319 - acc: 0.9727\n",
      "INFO:tensorflow:Assets written to: model_final_without_weights_after_epoch_5/assets\n",
      "1961/1961 [==============================] - 475s 242ms/step - loss: 0.1147 - acc: 0.9756\n",
      "INFO:tensorflow:Assets written to: model_final_without_weights_after_epoch_6/assets\n",
      "1961/1961 [==============================] - 472s 241ms/step - loss: 0.1003 - acc: 0.9788\n",
      "INFO:tensorflow:Assets written to: model_final_without_weights_after_epoch_7/assets\n",
      "1961/1961 [==============================] - 464s 237ms/step - loss: 0.0901 - acc: 0.9815\n",
      "INFO:tensorflow:Assets written to: model_final_without_weights_after_epoch_8/assets\n",
      "1961/1961 [==============================] - 467s 238ms/step - loss: 0.1017 - acc: 0.9815\n",
      "INFO:tensorflow:Assets written to: model_final_without_weights_after_epoch_9/assets\n",
      "1961/1961 [==============================] - 463s 236ms/step - loss: 0.0989 - acc: 0.9822\n",
      "INFO:tensorflow:Assets written to: model_final_without_weights_after_epoch_10/assets\n",
      "1961/1961 [==============================] - 462s 236ms/step - loss: 0.0999 - acc: 0.9827\n",
      "INFO:tensorflow:Assets written to: model_final_without_weights_after_epoch_11/assets\n",
      "1961/1961 [==============================] - 462s 235ms/step - loss: 0.0988 - acc: 0.9820\n",
      "INFO:tensorflow:Assets written to: model_final_without_weights_after_epoch_12/assets\n",
      "1961/1961 [==============================] - 461s 235ms/step - loss: 0.1066 - acc: 0.9817\n",
      "INFO:tensorflow:Assets written to: model_final_without_weights_after_epoch_13/assets\n",
      "1961/1961 [==============================] - 462s 235ms/step - loss: 0.1002 - acc: 0.9834\n",
      "INFO:tensorflow:Assets written to: model_final_without_weights_after_epoch_14/assets\n",
      "1961/1961 [==============================] - 487s 248ms/step - loss: 0.1159 - acc: 0.9814\n",
      "INFO:tensorflow:Assets written to: model_final_without_weights_after_epoch_15/assets\n",
      "1961/1961 [==============================] - 483s 246ms/step - loss: 0.1108 - acc: 0.9816\n",
      "INFO:tensorflow:Assets written to: model_final_without_weights_after_epoch_16/assets\n",
      "1961/1961 [==============================] - 496s 253ms/step - loss: 0.1106 - acc: 0.9817\n",
      "INFO:tensorflow:Assets written to: model_final_without_weights_after_epoch_17/assets\n",
      "1961/1961 [==============================] - 497s 254ms/step - loss: 0.1365 - acc: 0.9799\n",
      "INFO:tensorflow:Assets written to: model_final_without_weights_after_epoch_18/assets\n",
      "1961/1961 [==============================] - 482s 246ms/step - loss: 0.1381 - acc: 0.9798\n",
      "INFO:tensorflow:Assets written to: model_final_without_weights_after_epoch_19/assets\n",
      "1961/1961 [==============================] - 527s 269ms/step - loss: 0.1341 - acc: 0.9813\n",
      "INFO:tensorflow:Assets written to: model_final_without_weights_after_epoch_20/assets\n",
      "1961/1961 [==============================] - 711s 362ms/step - loss: 0.1346 - acc: 0.9809\n",
      "INFO:tensorflow:Assets written to: model_final_without_weights_after_epoch_21/assets\n",
      "1961/1961 [==============================] - 702s 358ms/step - loss: 0.1286 - acc: 0.9821\n",
      "INFO:tensorflow:Assets written to: model_final_without_weights_after_epoch_22/assets\n",
      "1961/1961 [==============================] - 772s 394ms/step - loss: 0.1446 - acc: 0.9808\n",
      "INFO:tensorflow:Assets written to: model_final_without_weights_after_epoch_23/assets\n",
      "1961/1961 [==============================] - 772s 394ms/step - loss: 0.1518 - acc: 0.9812\n",
      "INFO:tensorflow:Assets written to: model_final_without_weights_after_epoch_24/assets\n",
      "1961/1961 [==============================] - 780s 398ms/step - loss: 0.1452 - acc: 0.9802\n",
      "INFO:tensorflow:Assets written to: model_final_without_weights_after_epoch_25/assets\n",
      "1961/1961 [==============================] - 659s 336ms/step - loss: 0.1586 - acc: 0.9809\n",
      "INFO:tensorflow:Assets written to: model_final_without_weights_after_epoch_26/assets\n",
      "1961/1961 [==============================] - 540s 275ms/step - loss: 0.1410 - acc: 0.9807\n",
      "INFO:tensorflow:Assets written to: model_final_without_weights_after_epoch_27/assets\n",
      "1961/1961 [==============================] - 514s 262ms/step - loss: 0.1311 - acc: 0.9835\n",
      "INFO:tensorflow:Assets written to: model_final_without_weights_after_epoch_28/assets\n",
      "1961/1961 [==============================] - 502s 256ms/step - loss: 0.1484 - acc: 0.9827\n",
      "INFO:tensorflow:Assets written to: model_final_without_weights_after_epoch_29/assets\n",
      "1961/1961 [==============================] - 486s 248ms/step - loss: 0.1562 - acc: 0.9814\n",
      "INFO:tensorflow:Assets written to: model_final_without_weights_after_epoch_30/assets\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=1,\n",
    "        #validation_data=validation_generator,\n",
    "    )\n",
    "    \n",
    "    for item in items:\n",
    "        history_all[item].append(history.history[item][0])\n",
    "    \n",
    "    filename_model = 'model_final_without_weights_after_epoch_' + str(i+1)\n",
    "    model.save(filename_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "exotic-sequence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [3.4027109146118164,\n",
       "  0.892641544342041,\n",
       "  0.3014829456806183,\n",
       "  0.16853052377700806,\n",
       "  0.13191065192222595,\n",
       "  0.11468961834907532,\n",
       "  0.10032199323177338,\n",
       "  0.0900762751698494,\n",
       "  0.10165528953075409,\n",
       "  0.09890156239271164,\n",
       "  0.09989015012979507,\n",
       "  0.09875241667032242,\n",
       "  0.10663498938083649,\n",
       "  0.10022079944610596,\n",
       "  0.11589805036783218,\n",
       "  0.1107989251613617,\n",
       "  0.11062225699424744,\n",
       "  0.13650578260421753,\n",
       "  0.13805444538593292,\n",
       "  0.13413140177726746,\n",
       "  0.13459424674510956,\n",
       "  0.12857301533222198,\n",
       "  0.14463230967521667,\n",
       "  0.1517903208732605,\n",
       "  0.14522968232631683,\n",
       "  0.15858441591262817,\n",
       "  0.1410127580165863,\n",
       "  0.13110904395580292,\n",
       "  0.14842389523983002,\n",
       "  0.15623420476913452],\n",
       " 'acc': [0.27264147996902466,\n",
       "  0.7752811908721924,\n",
       "  0.9290469288825989,\n",
       "  0.9619730114936829,\n",
       "  0.972710371017456,\n",
       "  0.9756433367729187,\n",
       "  0.9787548780441284,\n",
       "  0.9814838171005249,\n",
       "  0.9814838171005249,\n",
       "  0.9822489619255066,\n",
       "  0.9827335476875305,\n",
       "  0.9820449352264404,\n",
       "  0.9816879034042358,\n",
       "  0.9834221601486206,\n",
       "  0.9813563227653503,\n",
       "  0.9815603494644165,\n",
       "  0.9817133545875549,\n",
       "  0.9799280762672424,\n",
       "  0.979775071144104,\n",
       "  0.9813053011894226,\n",
       "  0.9809227585792542,\n",
       "  0.9820704460144043,\n",
       "  0.9808207154273987,\n",
       "  0.981177806854248,\n",
       "  0.9802086353302002,\n",
       "  0.9808717370033264,\n",
       "  0.9806932210922241,\n",
       "  0.9835242033004761,\n",
       "  0.9827335476875305,\n",
       "  0.9813563227653503]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "synthetic-positive",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(history_all)\n",
    "df.to_excel('history_final_without_weights.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tender-found",
   "metadata": {},
   "source": [
    "## Define the final model with weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "interim-scenario",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 : training set size = 211\n",
      "Class 1 : training set size = 2221\n",
      "Class 2 : training set size = 2251\n",
      "Class 3 : training set size = 1411\n",
      "Class 4 : training set size = 1981\n",
      "Class 5 : training set size = 1861\n",
      "Class 6 : training set size = 421\n",
      "Class 7 : training set size = 1441\n",
      "Class 8 : training set size = 1411\n",
      "Class 9 : training set size = 1471\n",
      "Class 10 : training set size = 2011\n",
      "Class 11 : training set size = 1321\n",
      "Class 12 : training set size = 2101\n",
      "Class 13 : training set size = 2161\n",
      "Class 14 : training set size = 781\n",
      "Class 15 : training set size = 631\n",
      "Class 16 : training set size = 421\n",
      "Class 17 : training set size = 1111\n",
      "Class 18 : training set size = 1201\n",
      "Class 19 : training set size = 211\n",
      "Class 20 : training set size = 361\n",
      "Class 21 : training set size = 331\n",
      "Class 22 : training set size = 391\n",
      "Class 23 : training set size = 511\n",
      "Class 24 : training set size = 271\n",
      "Class 25 : training set size = 1501\n",
      "Class 26 : training set size = 601\n",
      "Class 27 : training set size = 241\n",
      "Class 28 : training set size = 541\n",
      "Class 29 : training set size = 271\n",
      "Class 30 : training set size = 451\n",
      "Class 31 : training set size = 781\n",
      "Class 32 : training set size = 241\n",
      "Class 33 : training set size = 690\n",
      "Class 34 : training set size = 421\n",
      "Class 35 : training set size = 1201\n",
      "Class 36 : training set size = 391\n",
      "Class 37 : training set size = 211\n",
      "Class 38 : training set size = 2071\n",
      "Class 39 : training set size = 301\n",
      "Class 40 : training set size = 361\n",
      "Class 41 : training set size = 241\n",
      "Class 42 : training set size = 241\n"
     ]
    }
   ],
   "source": [
    "size_per_class_list = []\n",
    "\n",
    "for i in range(len(all_classes)):\n",
    "    size_per_class_list.append([len(os.listdir(train_dir + \"/\" + all_classes[i]))])\n",
    "    print(\"Class\", i, \": training set size =\", len(os.listdir(train_dir + \"/\" + all_classes[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "endangered-fleece",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size_per_class = []\n",
    "\n",
    "for element in size_per_class_list:\n",
    "    train_size_per_class.append(element[0])\n",
    "    \n",
    "class_weights = {}\n",
    "\n",
    "i = 0\n",
    "for element in train_size_per_class:\n",
    "    class_weights[i] = max(train_size_per_class) / element\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "further-flower",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crazy-aggregate",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2), strides=2))\n",
    "model.add(layers.Dropout(0.1))\n",
    "model.add(layers.Conv2D(64, (5, 5), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2), strides=2))\n",
    "model.add(layers.Dropout(0.15))\n",
    "model.add(layers.Conv2D(128, (7, 7), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2), strides=2 ))\n",
    "model.add(layers.Dropout(0.15))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dropout(0.4))\n",
    "model.add(layers.Dense (43, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sacred-services",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "#compilation\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.RMSprop(lr=1e-4), metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "creative-minute",
   "metadata": {},
   "source": [
    "## Train the final model with weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faced-mitchell",
   "metadata": {},
   "outputs": [],
   "source": [
    "items = ['loss', 'acc']\n",
    "history_all = {}\n",
    "for item in items:\n",
    "    history_all[item] = []\n",
    "history_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unknown-broadway",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(30):\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=1,\n",
    "        #validation_data=validation_generator,\n",
    "        class_weight=class_weights\n",
    "    )\n",
    "    \n",
    "    for item in items:\n",
    "        history_all[item].append(history.history[item][0])\n",
    "    \n",
    "    filename_model = 'model_final_with_weights_after_epoch_' + str(i+1)\n",
    "    model.save(filename_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parallel-annex",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "japanese-evolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(history_all)\n",
    "df.to_excel('history_final_with_weights.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinct-metadata",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "damaged-northeast",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "velvet-reconstruction",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "starting-apartment",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coastal-lying",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deluxe-scott",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facial-tolerance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "special-struggle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displaying curves of loss and accuracy during training\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history[\"acc\"]\n",
    "val_acc = history.history[\"val_acc\"]\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, \"bo\", label=\"Training acc\")\n",
    "plt.plot(epochs, val_acc, \"b\", label=\"Validation acc\")\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-beatles",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
