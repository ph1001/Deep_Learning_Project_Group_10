{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "vulnerable-series",
   "metadata": {},
   "source": [
    "# Deep Learning Project - Lisbon traffic sign experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bound-domestic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "partial-spice",
   "metadata": {},
   "source": [
    "## Predicting test set images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "uniform-carry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a saved model\n",
    "model = keras.models.load_model('model_all_data_3ConvLayers_down_changed_architecture_100_100_16to30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "commercial-continuity",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = '/Users/philippmetzger/Documents/GitHub/Deep_Learning_Project_Group_10/Data/lisbon_traffic_signs'\n",
    "#test_dir = '/Users/philippmetzger/Documents/GitHub/Deep_Learning_Project_Group_10/Data/Meta'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civic-auction",
   "metadata": {},
   "source": [
    "##### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ranking-mystery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(100,100),\n",
    "    batch_size=20,\n",
    "    shuffle=False,\n",
    "    #class_mode=None,\n",
    "    class_mode=\"categorical\",\n",
    "    color_mode=\"grayscale\"\n",
    "    )\n",
    "\n",
    "x_test=np.concatenate([test_generator.next()[0] for i in range(test_generator.__len__())])\n",
    "\n",
    "test_datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
    "\n",
    "test_datagen.fit(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "planned-calculation",
   "metadata": {},
   "source": [
    "##### Re-Creating the generators with the normalized image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "amended-investing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(100, 100),\n",
    "        batch_size=20,\n",
    "        shuffle=False,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode=None)\n",
    "\n",
    "test_generator.reset() \n",
    "pred_scores = model.predict_generator(test_generator)\n",
    "class_pred = np.argmax(pred_scores, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "union-shelf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17, 17, 17, 17, 17,  1,  3,  3,  1,  3, 33, 33, 33, 33, 33, 33, 33,\n",
       "       33, 33, 33, 33, 33, 33, 33, 33, 29, 29, 29, 29])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "refined-closing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(class_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "domestic-cambridge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8620689655172413"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(class_pred)-4) / len(class_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "brief-armor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 33,\n",
       " 33,\n",
       " 33,\n",
       " 33,\n",
       " 33,\n",
       " 33,\n",
       " 33,\n",
       " 33,\n",
       " 33,\n",
       " 33,\n",
       " 33,\n",
       " 33,\n",
       " 33,\n",
       " 33,\n",
       " 33,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 29]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(class_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nutritional-approval",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
