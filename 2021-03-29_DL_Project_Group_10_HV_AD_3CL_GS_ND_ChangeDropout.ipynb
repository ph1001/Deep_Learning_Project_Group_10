{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "determined-remark",
   "metadata": {},
   "source": [
    "# Deep Learning Project - Traffic Signs Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "authentic-cyprus",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "prescription-conspiracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_hist_to_excel(filename):\n",
    "    df = pd.DataFrame(history.history)\n",
    "    df.to_excel(filename + '.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vietnamese-attention",
   "metadata": {},
   "source": [
    "## Overview of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civic-alberta",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting the training directory (the training images can be found there, already sorted by class into folders)\n",
    "base_training_dir = \"/Users/henriquevaz/NOVA IMS/YEAR 1/SPRING SEMESTER/DL/Project/my_notebooks/Data/Training/Final_Training/Images/\"\n",
    "#base_training_dir = \"/Users/philippmetzger/Documents/GitHub/Deep_Learning_Project_Group_10/Data/GTSRB_Final_Training_Images/GTSRB/Final_Training/Images/\"\n",
    "#base_training_dir = \"/Users/franz/Desktop/DL Project/Train/Final_Training/Images\"\n",
    "\n",
    "#setting the directory where the selected training and validation images will be stored in\n",
    "created_dir = \"/Users/henriquevaz/NOVA IMS/YEAR 1/SPRING SEMESTER/DL/Project/my_notebooks/Data/Selected\"\n",
    "#created_dir = \"/Users/philippmetzger/Documents/GitHub/Deep_Learning_Project_Group_10/Data/Selected\"\n",
    "#created_dir = \"/Users/franz/Desktop/DL Project/Selected\"\n",
    "\n",
    "#storing all the folder names that belong to the respective classes\n",
    "all_classes = sorted(i for i in os.listdir(base_training_dir) if i.startswith(\"0\"))\n",
    "\n",
    "print(\"There are\", len(all_classes), \"different classes within the training data!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passing-copper",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the number of images within each class of the training data\n",
    "amount_per_class = {}\n",
    "\n",
    "for i in range(len(all_classes)):\n",
    "    directory = base_training_dir + \"/\" + all_classes[i]\n",
    "    amount_per_class[i] = len(sorted(i for i in os.listdir(directory) if i.startswith(\"0\")))\n",
    "\n",
    "amount_per_class_df = pd.DataFrame.from_dict(amount_per_class, orient='index').rename(columns={0:\"amount\"})\n",
    "amount_per_class_df.index.name = 'class'\n",
    "\n",
    "#remove the \"#\" of the following line to display the number of images within each class\n",
    "#amount_per_class_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smart-notification",
   "metadata": {},
   "outputs": [],
   "source": [
    "#displaying the number of images per class visually\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20,8)\n",
    "fig, ax = plt.subplots()\n",
    "plt.bar(amount_per_class_df.index, amount_per_class_df.amount)\n",
    "plt.title(\"Number of images per class\", fontsize=20)\n",
    "plt.xlabel('class', fontsize=18)\n",
    "plt.ylabel('number of images', fontsize=18)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.xticks(amount_per_class_df.index)\n",
    "plt.grid(axis=\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contained-certification",
   "metadata": {},
   "source": [
    "As it can be seen in the bar chart, the dataset is highly unbalanced. Some classes have over 2000 instances, while others only have 210."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exempt-married",
   "metadata": {},
   "outputs": [],
   "source": [
    "#displaying the 20 classes with the fewest images\n",
    "amount_per_class_df.sort_values(\"amount\").head(20).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "favorite-romance",
   "metadata": {},
   "source": [
    "Within each class, there are several groups of images, that belong together (these are basically all images of the very same traffic sign, that just differ in that they were made as a series while approaching the actual sign). These series of images shouldn't be splitted later when the data is split into training and validation sets, so some precautions might be useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closed-romania",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the size(=amount of images) of these series and whether they are all having the same size\n",
    "\n",
    "#running a for loop over all classes\n",
    "for i in range(len(all_classes)):\n",
    "    directory = base_training_dir + \"/\" + all_classes[i]\n",
    "    \n",
    "    #get the names of all images within a class\n",
    "    list_of_images = sorted(i for i in os.listdir(directory) if i.startswith(\"0\"))\n",
    "\n",
    "    image_series = []\n",
    "    \n",
    "    #store all the prefixes of the images (which correspond to the series they belong to)\n",
    "    for element in list_of_images:\n",
    "        image_series.append(element.split(\"_\")[0])\n",
    "    \n",
    "    #count the frequency of each prefix, which equals the size of each respective series\n",
    "    image_counts = pd.Series(image_series).value_counts().sort_index()\n",
    "\n",
    "    for element in image_counts.values.tolist():\n",
    "        if element != image_counts.values.tolist()[0]:\n",
    "            #this line will show if there is a series that contains not the same number of images than the others\n",
    "            print(\"There is a series whose number doesn't match the others in class\", all_classes[i], \", with the prefix\", image_counts.sort_values().index[0], \"!\\nIt only contains\", element, \"images.\")\n",
    "            \n",
    "\n",
    "#apart from only one series, all others consist of exactly 30 images\n",
    "print(\"All the other series of images contain exactly\", image_counts.values.tolist()[0], \"images!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "czech-watson",
   "metadata": {},
   "source": [
    "## Split into training and validation datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adverse-contents",
   "metadata": {},
   "source": [
    "As already mentioned, it is important for the split into training and validation sets that the individual image series stay together. As a first approach, there will be 210 images used per class, as this number corresponds to the amount of images in the \"smallest\" class. This will fix the problem of imbalance in the dataset. Subsequently, the data will be splitted by a 5:2 (150:60) ratio into training and validation set, in order to guarantee that the series will stay together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ordinary-sensitivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_dir = \"/Users/henriquevaz/NOVA IMS/YEAR 1/SPRING SEMESTER/DL/Project/my_notebooks/Data/Selected/train_all\"\n",
    "new_val_dir = \"/Users/henriquevaz/NOVA IMS/YEAR 1/SPRING SEMESTER/DL/Project/my_notebooks/Data/Selected/val_all\"\n",
    "\n",
    "#new_train_dir = \"/Users/franz/Desktop/DL Project/Selected/train_all\"\n",
    "#new_val_dir = \"/Users/franz/Desktop/DL Project/Selected/val_all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "color-hardware",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(all_classes)):\n",
    "    os.mkdir(new_train_dir + \"/\" + all_classes[i])\n",
    "    os.mkdir(new_val_dir + \"/\" + all_classes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absolute-jones",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "for i in range(len(all_classes)):\n",
    "    \n",
    "    list_ = os.listdir(base_training_dir + \"/\" + all_classes[i])\n",
    "    random.shuffle(list_)\n",
    "    new_list = []\n",
    "    for element in list_:\n",
    "        if element.startswith(\"000\"):\n",
    "            new_list.append(element)\n",
    "    \n",
    "    new_list = sorted(new_list)\n",
    "    for image in range(len(new_list)):\n",
    "        \n",
    "        \n",
    "        #setting the cut off according to the next closest number in steps of 30 according to a 70:30 ratio\n",
    "        if len(new_list) == 210 or len(new_list) == 240:\n",
    "            cut = 60\n",
    "        elif len(new_list) == 270 or len(new_list) == 300 or len(new_list) == 330:\n",
    "            cut = 90\n",
    "        elif len(new_list) == 360 or len(new_list) == 390 or len(new_list) == 420:\n",
    "            cut = 120\n",
    "        elif len(new_list) == 450 or len(new_list) == 510 or len(new_list) == 540:\n",
    "            cut = 150\n",
    "        elif len(new_list) == 600 or len(new_list) == 630:\n",
    "            cut = 180\n",
    "        elif len(new_list) == 689:\n",
    "            cut = 210 - 1\n",
    "        elif len(new_list) == 780:\n",
    "            cut = 240\n",
    "        elif len(new_list) == 1110:\n",
    "            cut = 330\n",
    "        elif len(new_list) == 1200:\n",
    "            cut = 360\n",
    "        elif len(new_list) == 1320:\n",
    "            cut = 390\n",
    "        elif len(new_list) == 1410 or len(new_list) == 1440:\n",
    "            cut = 420\n",
    "        elif len(new_list) == 1470 or len(new_list) == 1500:\n",
    "            cut = 450\n",
    "        elif len(new_list) == 1860:\n",
    "            cut = 570\n",
    "        elif len(new_list) == 1980 or len(new_list) == 2010:\n",
    "            cut = 600\n",
    "        elif len(new_list) == 2070 or len(new_list) == 2100:\n",
    "            cut = 630\n",
    "        elif len(new_list) == 2160 or len(new_list) == 2220:\n",
    "            cut = 660\n",
    "        elif len(new_list) == 2250:\n",
    "            cut = 690\n",
    "         \n",
    "        \n",
    "        if image < len(new_list) - cut:\n",
    "            \n",
    "            src = base_training_dir + \"/\" + all_classes[i] + \"/\" + new_list[image]\n",
    "            dst = new_train_dir + \"/\" + all_classes[i] + \"/\"  + new_list[image]\n",
    "            shutil.copyfile(src, dst)\n",
    "            \n",
    "        else:\n",
    "            src = base_training_dir + \"/\" + all_classes[i] + \"/\" + new_list[image]\n",
    "            dst = new_val_dir + \"/\" + all_classes[i] + \"/\"  + new_list[image]\n",
    "            shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "timely-diary",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_per_class_list = []\n",
    "\n",
    "for i in range(len(all_classes)):\n",
    "    size_per_class_list.append([len(os.listdir(new_train_dir + \"/\" + all_classes[i])), len(os.listdir(new_val_dir + \"/\" + all_classes[i]))])\n",
    "    print(\"Class\", i, \": training set size =\", len(os.listdir(new_train_dir + \"/\" + all_classes[i])), \"; validation set size:\", len(os.listdir(new_val_dir + \"/\" + all_classes[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liable-climate",
   "metadata": {},
   "source": [
    "Now, there should be exactly 150 images within the train folder of each class and 60 images within the validation folder. Having 43 different classes, this means that there are a total of 6,450 (150x43) training images and another 2,580 (60x43) validation images. A sanity check will show if this worked correctly:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "close-bloom",
   "metadata": {},
   "source": [
    "As it can be seen, it worked correctly!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enormous-council",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infinite-attraction",
   "metadata": {},
   "source": [
    "After running the upper part once, the notebook can be started from here from now on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dental-decrease",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#this cell is optional and the notebook should be runned from here once the upper part has been executed once\n",
    "\n",
    "import os, shutil\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "beginning-dover",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = new_train_dir\n",
    "validation_dir = new_val_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "individual-cliff",
   "metadata": {},
   "source": [
    "##### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "improving-tribute",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 27450 images belonging to 43 classes.\n",
      "Found 11759 images belonging to 43 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150,150),\n",
    "    batch_size=20,\n",
    "    class_mode=\"categorical\",\n",
    "    color_mode=\"grayscale\"\n",
    "    )\n",
    "\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(150,150),\n",
    "    batch_size=20,\n",
    "    class_mode=\"categorical\",\n",
    "    color_mode=\"grayscale\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "continuing-threat",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=np.concatenate([train_generator.next()[0] for i in range(train_generator.__len__())])\n",
    "x_val=np.concatenate([validation_generator.next()[0] for i in range(validation_generator.__len__())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "turkish-mozambique",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
    "test_datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
    "\n",
    "train_datagen.fit(x_train)\n",
    "test_datagen.fit(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "happy-amplifier",
   "metadata": {},
   "source": [
    "##### Re-Creating the generators with the normalized image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "particular-fireplace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 27450 images belonging to 43 classes.\n",
      "Found 11759 images belonging to 43 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150,150),\n",
    "    batch_size=20,\n",
    "    class_mode=\"categorical\",\n",
    "    color_mode=\"grayscale\"\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(150,150),\n",
    "    batch_size=20,\n",
    "    class_mode=\"categorical\",\n",
    "    color_mode=\"grayscale\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "peripheral-exercise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data batch shape: (20, 150, 150, 1)\n",
      "labels batch shape: (20, 43)\n"
     ]
    }
   ],
   "source": [
    "sys.modules['Image'] = Image\n",
    "\n",
    "for data_batch, labels_batch in train_generator:\n",
    "    print('data batch shape:', data_batch.shape)\n",
    "    print('labels batch shape:', labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plastic-dominican",
   "metadata": {},
   "source": [
    "## Draft of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coated-sector",
   "metadata": {},
   "source": [
    "### Base model (Using the 'Down' Version) - (0.15 ; 0.15 ; 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "placed-representation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (2, 2), activation='relu', input_shape=(150, 150, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.15))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2) ))\n",
    "model.add(layers.Dropout(0.15))\n",
    "model.add(layers.Conv2D(128, (4, 4), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2) ))\n",
    "model.add(layers.Dropout(0.15))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense (43, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "collect-dimension",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 149, 149, 32)      160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 72, 72, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 33, 33, 128)       131200    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               16777728  \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 43)                22059     \n",
      "=================================================================\n",
      "Total params: 16,949,643\n",
      "Trainable params: 16,949,643\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "central-inquiry",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "#compilation\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.RMSprop(lr=1e-4), metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "prostate-funeral",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1373/1373 [==============================] - 236s 172ms/step - loss: 48.8532 - acc: 0.2982 - val_loss: 250.6489 - val_acc: 0.7299\n",
      "Epoch 2/10\n",
      "1373/1373 [==============================] - 234s 170ms/step - loss: 1523.4500 - acc: 0.6536 - val_loss: 6988.4404 - val_acc: 0.7923\n",
      "Epoch 3/10\n",
      "1373/1373 [==============================] - 234s 170ms/step - loss: 21203.8718 - acc: 0.7156 - val_loss: 41043.4297 - val_acc: 0.8193\n",
      "Epoch 4/10\n",
      "1373/1373 [==============================] - 233s 170ms/step - loss: 85391.4517 - acc: 0.7660 - val_loss: 150506.2031 - val_acc: 0.8370\n",
      "Epoch 5/10\n",
      "1373/1373 [==============================] - 233s 170ms/step - loss: 239056.8945 - acc: 0.7936 - val_loss: 300831.5938 - val_acc: 0.8597\n",
      "Epoch 6/10\n",
      "1373/1373 [==============================] - 249s 182ms/step - loss: 549996.7753 - acc: 0.8026 - val_loss: 899185.1875 - val_acc: 0.8380\n",
      "Epoch 7/10\n",
      "1373/1373 [==============================] - 246s 179ms/step - loss: 1494548.4599 - acc: 0.7762 - val_loss: 1586297.6250 - val_acc: 0.8589\n",
      "Epoch 8/10\n",
      "1373/1373 [==============================] - 245s 179ms/step - loss: 1966673.0043 - acc: 0.8144 - val_loss: 2248802.5000 - val_acc: 0.8646\n",
      "Epoch 9/10\n",
      "1373/1373 [==============================] - 247s 180ms/step - loss: 3286120.0035 - acc: 0.8198 - val_loss: 3688171.0000 - val_acc: 0.8698\n",
      "Epoch 10/10\n",
      "1373/1373 [==============================] - 253s 184ms/step - loss: 5007906.9165 - acc: 0.8183 - val_loss: 5766178.5000 - val_acc: 0.8640\n"
     ]
    }
   ],
   "source": [
    "# 1-10\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "meaning-modem",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_hist_to_excel('history_model_all_data_3ConvLayers_down_015_015_015_1to10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "reliable-arizona",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1373/1373 [==============================] - 246s 179ms/step - loss: 7312574.5000 - acc: 0.8320 - val_loss: 8148077.0000 - val_acc: 0.8743\n",
      "Epoch 2/10\n",
      "1373/1373 [==============================] - 245s 179ms/step - loss: 9607637.0000 - acc: 0.8418 - val_loss: 11119907.0000 - val_acc: 0.8671\n",
      "Epoch 3/10\n",
      "1373/1373 [==============================] - 241s 176ms/step - loss: 12745489.0000 - acc: 0.8396 - val_loss: 14923061.0000 - val_acc: 0.8717\n",
      "Epoch 4/10\n",
      "1373/1373 [==============================] - 232s 169ms/step - loss: 13477982.0000 - acc: 0.8597 - val_loss: 17616872.0000 - val_acc: 0.8762\n",
      "Epoch 5/10\n",
      "1373/1373 [==============================] - 226s 165ms/step - loss: 18227464.0000 - acc: 0.8554 - val_loss: 26183722.0000 - val_acc: 0.8612\n",
      "Epoch 6/10\n",
      "1373/1373 [==============================] - 229s 167ms/step - loss: 22722914.0000 - acc: 0.8570 - val_loss: 27556662.0000 - val_acc: 0.8709\n",
      "Epoch 7/10\n",
      "1373/1373 [==============================] - 230s 167ms/step - loss: 26157604.0000 - acc: 0.8618 - val_loss: 35505672.0000 - val_acc: 0.8724\n",
      "Epoch 8/10\n",
      "1373/1373 [==============================] - 229s 167ms/step - loss: 27957200.0000 - acc: 0.8709 - val_loss: 49920648.0000 - val_acc: 0.8631\n",
      "Epoch 9/10\n",
      "1373/1373 [==============================] - 228s 166ms/step - loss: 33336168.0000 - acc: 0.8728 - val_loss: 55931804.0000 - val_acc: 0.8744\n",
      "Epoch 10/10\n",
      "1373/1373 [==============================] - 225s 164ms/step - loss: 38801104.0000 - acc: 0.8739 - val_loss: 64067572.0000 - val_acc: 0.8822\n"
     ]
    }
   ],
   "source": [
    "# 11-20\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "perceived-minutes",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_hist_to_excel('history_model_all_data_3ConvLayers_down_015_015_015_11to20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "interesting-cylinder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1373/1373 [==============================] - 226s 164ms/step - loss: 41107340.0000 - acc: 0.8793 - val_loss: 67325688.0000 - val_acc: 0.8800\n",
      "Epoch 2/10\n",
      "1373/1373 [==============================] - 227s 166ms/step - loss: 41805876.0000 - acc: 0.8871 - val_loss: 76303464.0000 - val_acc: 0.8785\n",
      "Epoch 3/10\n",
      "1373/1373 [==============================] - 228s 166ms/step - loss: 47182948.0000 - acc: 0.8851 - val_loss: 95114344.0000 - val_acc: 0.8744\n",
      "Epoch 4/10\n",
      "1373/1373 [==============================] - 227s 165ms/step - loss: 48014304.0000 - acc: 0.8928 - val_loss: 104047136.0000 - val_acc: 0.8809\n",
      "Epoch 5/10\n",
      "1373/1373 [==============================] - 227s 166ms/step - loss: 48507540.0000 - acc: 0.8985 - val_loss: 113504728.0000 - val_acc: 0.8849\n",
      "Epoch 6/10\n",
      "1373/1373 [==============================] - 223s 163ms/step - loss: 54361996.0000 - acc: 0.8971 - val_loss: 108207040.0000 - val_acc: 0.8900\n",
      "Epoch 7/10\n",
      "1373/1373 [==============================] - 215s 156ms/step - loss: 58774708.0000 - acc: 0.9009 - val_loss: 122800200.0000 - val_acc: 0.8871\n",
      "Epoch 8/10\n",
      "1373/1373 [==============================] - 214s 156ms/step - loss: 62532116.0000 - acc: 0.9026 - val_loss: 132481392.0000 - val_acc: 0.8870\n",
      "Epoch 9/10\n",
      "1373/1373 [==============================] - 214s 156ms/step - loss: 70984008.0000 - acc: 0.9020 - val_loss: 158322288.0000 - val_acc: 0.8791\n",
      "Epoch 10/10\n",
      "1373/1373 [==============================] - 214s 156ms/step - loss: 70497720.0000 - acc: 0.9068 - val_loss: 159174384.0000 - val_acc: 0.8927\n"
     ]
    }
   ],
   "source": [
    "# 21-30\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "excess-chair",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_hist_to_excel('history_model_all_data_3ConvLayers_down_015_015_015_21to30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "median-blake",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1373/1373 [==============================] - 215s 156ms/step - loss: 73172552.0000 - acc: 0.9089 - val_loss: 176515856.0000 - val_acc: 0.8883\n",
      "Epoch 2/10\n",
      "1373/1373 [==============================] - 215s 156ms/step - loss: 76192360.0000 - acc: 0.9109 - val_loss: 203744112.0000 - val_acc: 0.8727\n",
      "Epoch 3/10\n",
      "1373/1373 [==============================] - 215s 156ms/step - loss: 72098104.0000 - acc: 0.9168 - val_loss: 210290576.0000 - val_acc: 0.8931\n",
      "Epoch 4/10\n",
      "1373/1373 [==============================] - 214s 156ms/step - loss: 83578160.0000 - acc: 0.9128 - val_loss: 228597408.0000 - val_acc: 0.8822\n",
      "Epoch 5/10\n",
      "1373/1373 [==============================] - 214s 156ms/step - loss: 83012336.0000 - acc: 0.9160 - val_loss: 220409952.0000 - val_acc: 0.8832\n",
      "Epoch 6/10\n",
      "1373/1373 [==============================] - 214s 156ms/step - loss: 81480304.0000 - acc: 0.9221 - val_loss: 224112320.0000 - val_acc: 0.8895\n",
      "Epoch 7/10\n",
      "1373/1373 [==============================] - 214s 156ms/step - loss: 81231600.0000 - acc: 0.9230 - val_loss: 264817792.0000 - val_acc: 0.8940\n",
      "Epoch 8/10\n",
      "1373/1373 [==============================] - 214s 156ms/step - loss: 74887368.0000 - acc: 0.9259 - val_loss: 273821248.0000 - val_acc: 0.8901\n",
      "Epoch 9/10\n",
      "1373/1373 [==============================] - 214s 156ms/step - loss: 86723840.0000 - acc: 0.9218 - val_loss: 295322560.0000 - val_acc: 0.8828\n",
      "Epoch 10/10\n",
      "1373/1373 [==============================] - 214s 156ms/step - loss: 94069312.0000 - acc: 0.9211 - val_loss: 326438848.0000 - val_acc: 0.8871\n"
     ]
    }
   ],
   "source": [
    "# 31-40\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "unauthorized-cheat",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_hist_to_excel('history_model_all_data_3ConvLayers_down_015_015_015_31to40')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "figured-script",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1373/1373 [==============================] - 215s 156ms/step - loss: 93105448.0000 - acc: 0.9252 - val_loss: 317887232.0000 - val_acc: 0.8897\n",
      "Epoch 2/10\n",
      "1373/1373 [==============================] - 215s 156ms/step - loss: 98529232.0000 - acc: 0.9251 - val_loss: 347565312.0000 - val_acc: 0.8938\n",
      "Epoch 3/10\n",
      "1373/1373 [==============================] - 215s 156ms/step - loss: 98141536.0000 - acc: 0.9260 - val_loss: 354840480.0000 - val_acc: 0.8991\n",
      "Epoch 4/10\n",
      "1373/1373 [==============================] - 215s 156ms/step - loss: 97342224.0000 - acc: 0.9259 - val_loss: 358056544.0000 - val_acc: 0.8906\n",
      "Epoch 5/10\n",
      "1373/1373 [==============================] - 215s 156ms/step - loss: 98727488.0000 - acc: 0.9283 - val_loss: 434362688.0000 - val_acc: 0.8867\n",
      "Epoch 6/10\n",
      "1373/1373 [==============================] - 215s 156ms/step - loss: 101386488.0000 - acc: 0.9299 - val_loss: 462194016.0000 - val_acc: 0.8904\n",
      "Epoch 7/10\n",
      "1373/1373 [==============================] - 214s 156ms/step - loss: 108445232.0000 - acc: 0.9307 - val_loss: 448308288.0000 - val_acc: 0.8888\n",
      "Epoch 8/10\n",
      "1373/1373 [==============================] - 214s 156ms/step - loss: 98688792.0000 - acc: 0.9334 - val_loss: 432641312.0000 - val_acc: 0.8920\n",
      "Epoch 9/10\n",
      "1373/1373 [==============================] - 215s 157ms/step - loss: 96855128.0000 - acc: 0.9336 - val_loss: 451999648.0000 - val_acc: 0.8928\n",
      "Epoch 10/10\n",
      "1373/1373 [==============================] - 217s 158ms/step - loss: 101231344.0000 - acc: 0.9346 - val_loss: 455148672.0000 - val_acc: 0.8945\n"
     ]
    }
   ],
   "source": [
    "# 41-50\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "stuffed-accreditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_hist_to_excel('history_model_all_data_3ConvLayers_down_015_015_015_41to50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "special-struggle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Displaying curves of loss and accuracy during training\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history[\"acc\"]\n",
    "val_acc = history.history[\"val_acc\"]\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, \"bo\", label=\"Training acc\")\n",
    "plt.plot(epochs, val_acc, \"b\", label=\"Validation acc\")\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beginning-destruction",
   "metadata": {},
   "source": [
    "### Base model (Using the 'Down' Version) - (0.15 ; 0.1 ; 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "peripheral-deviation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 149, 149, 32)      160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 72, 72, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 33, 33, 128)       131200    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               16777728  \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 43)                22059     \n",
      "=================================================================\n",
      "Total params: 16,949,643\n",
      "Trainable params: 16,949,643\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (2, 2), activation='relu', input_shape=(150, 150, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.15))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2) ))\n",
    "model.add(layers.Dropout(0.1))\n",
    "model.add(layers.Conv2D(128, (4, 4), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2) ))\n",
    "model.add(layers.Dropout(0.1))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense (43, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "optional-wheel",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "#compilation\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.RMSprop(lr=1e-4), metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "noble-coast",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1373/1373 [==============================] - 221s 161ms/step - loss: 328.0956 - acc: 0.6317 - val_loss: 652.2593 - val_acc: 0.7604\n",
      "Epoch 2/25\n",
      "1373/1373 [==============================] - 216s 157ms/step - loss: 6455.9839 - acc: 0.7295 - val_loss: 10189.2764 - val_acc: 0.8252\n",
      "Epoch 3/25\n",
      "1373/1373 [==============================] - 219s 159ms/step - loss: 44854.7656 - acc: 0.7553 - val_loss: 56825.4805 - val_acc: 0.8418\n",
      "Epoch 4/25\n",
      "1373/1373 [==============================] - 217s 158ms/step - loss: 121934.5625 - acc: 0.8003 - val_loss: 170586.8750 - val_acc: 0.8353\n",
      "Epoch 5/25\n",
      "1373/1373 [==============================] - 218s 159ms/step - loss: 323920.2188 - acc: 0.8073 - val_loss: 371333.5938 - val_acc: 0.8565\n",
      "Epoch 6/25\n",
      "1373/1373 [==============================] - 218s 159ms/step - loss: 694845.1875 - acc: 0.8098 - val_loss: 716706.8125 - val_acc: 0.8627\n",
      "Epoch 7/25\n",
      "1373/1373 [==============================] - 217s 158ms/step - loss: 1315244.3750 - acc: 0.8176 - val_loss: 1396392.5000 - val_acc: 0.8673\n",
      "Epoch 8/25\n",
      "1373/1373 [==============================] - 218s 159ms/step - loss: 1831718.1250 - acc: 0.8392 - val_loss: 2196445.0000 - val_acc: 0.8767\n",
      "Epoch 9/25\n",
      "1373/1373 [==============================] - 220s 160ms/step - loss: 2701310.0000 - acc: 0.8462 - val_loss: 3077954.7500 - val_acc: 0.8741\n",
      "Epoch 10/25\n",
      "1373/1373 [==============================] - 220s 161ms/step - loss: 4534727.0000 - acc: 0.8417 - val_loss: 5563932.5000 - val_acc: 0.8571\n",
      "Epoch 11/25\n",
      "1373/1373 [==============================] - 219s 160ms/step - loss: 6376921.0000 - acc: 0.8399 - val_loss: 7963246.0000 - val_acc: 0.8780\n",
      "Epoch 12/25\n",
      "1373/1373 [==============================] - 225s 164ms/step - loss: 7829505.5000 - acc: 0.8533 - val_loss: 10801242.0000 - val_acc: 0.8820\n",
      "Epoch 13/25\n",
      "1373/1373 [==============================] - 223s 162ms/step - loss: 10037913.0000 - acc: 0.8592 - val_loss: 13448337.0000 - val_acc: 0.8708\n",
      "Epoch 14/25\n",
      "1373/1373 [==============================] - 221s 161ms/step - loss: 10342059.0000 - acc: 0.8777 - val_loss: 16312935.0000 - val_acc: 0.8831\n",
      "Epoch 15/25\n",
      "1373/1373 [==============================] - 217s 158ms/step - loss: 12979521.0000 - acc: 0.8779 - val_loss: 19663230.0000 - val_acc: 0.8820\n",
      "Epoch 16/25\n",
      "1373/1373 [==============================] - 221s 161ms/step - loss: 15591975.0000 - acc: 0.8801 - val_loss: 25084894.0000 - val_acc: 0.8852\n",
      "Epoch 17/25\n",
      "1373/1373 [==============================] - 222s 162ms/step - loss: 18205192.0000 - acc: 0.8836 - val_loss: 27134158.0000 - val_acc: 0.8911\n",
      "Epoch 18/25\n",
      "1373/1373 [==============================] - 221s 161ms/step - loss: 19949660.0000 - acc: 0.8883 - val_loss: 39240792.0000 - val_acc: 0.8691\n",
      "Epoch 19/25\n",
      "1373/1373 [==============================] - 220s 160ms/step - loss: 21137058.0000 - acc: 0.8964 - val_loss: 42817360.0000 - val_acc: 0.8789\n",
      "Epoch 20/25\n",
      "1373/1373 [==============================] - 218s 159ms/step - loss: 26005642.0000 - acc: 0.8908 - val_loss: 49213780.0000 - val_acc: 0.8860\n",
      "Epoch 21/25\n",
      "1373/1373 [==============================] - 221s 161ms/step - loss: 28448540.0000 - acc: 0.8986 - val_loss: 54299204.0000 - val_acc: 0.8931\n",
      "Epoch 22/25\n",
      "1373/1373 [==============================] - 219s 159ms/step - loss: 29337786.0000 - acc: 0.9047 - val_loss: 60255736.0000 - val_acc: 0.8830\n",
      "Epoch 23/25\n",
      "1373/1373 [==============================] - 223s 163ms/step - loss: 33889604.0000 - acc: 0.9027 - val_loss: 66193100.0000 - val_acc: 0.8946\n",
      "Epoch 24/25\n",
      "1373/1373 [==============================] - 222s 161ms/step - loss: 35826880.0000 - acc: 0.9052 - val_loss: 75515544.0000 - val_acc: 0.8891\n",
      "Epoch 25/25\n",
      "1373/1373 [==============================] - 218s 159ms/step - loss: 39825360.0000 - acc: 0.9077 - val_loss: 90167848.0000 - val_acc: 0.8819\n"
     ]
    }
   ],
   "source": [
    "# 1-25\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=25,\n",
    "    validation_data=validation_generator,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "threaded-daisy",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_hist_to_excel('history_model_all_data_3ConvLayers_down_015_01_01_1to25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comprehensive-divorce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1373/1373 [==============================] - 221s 161ms/step - loss: 43229824.0000 - acc: 0.9077 - val_loss: 101071472.0000 - val_acc: 0.8810\n",
      "Epoch 2/25\n",
      "1373/1373 [==============================] - 227s 165ms/step - loss: 49137588.0000 - acc: 0.9071 - val_loss: 114774064.0000 - val_acc: 0.8846\n",
      "Epoch 3/25\n",
      "1373/1373 [==============================] - 222s 161ms/step - loss: 47521108.0000 - acc: 0.9144 - val_loss: 120511304.0000 - val_acc: 0.8948\n",
      "Epoch 4/25\n",
      "1373/1373 [==============================] - 223s 163ms/step - loss: 54632904.0000 - acc: 0.9097 - val_loss: 133338928.0000 - val_acc: 0.8933\n",
      "Epoch 5/25\n",
      "1373/1373 [==============================] - 225s 164ms/step - loss: 56727188.0000 - acc: 0.9137 - val_loss: 139691728.0000 - val_acc: 0.8872\n",
      "Epoch 6/25\n",
      "1373/1373 [==============================] - 223s 163ms/step - loss: 63928776.0000 - acc: 0.9150 - val_loss: 144076880.0000 - val_acc: 0.8965\n",
      "Epoch 7/25\n",
      "1373/1373 [==============================] - 217s 158ms/step - loss: 64677408.0000 - acc: 0.9157 - val_loss: 189702832.0000 - val_acc: 0.8895\n",
      "Epoch 8/25\n",
      "1373/1373 [==============================] - 214s 156ms/step - loss: 70401936.0000 - acc: 0.9182 - val_loss: 179410912.0000 - val_acc: 0.8948\n",
      "Epoch 9/25\n",
      "1373/1373 [==============================] - 215s 157ms/step - loss: 70802656.0000 - acc: 0.9230 - val_loss: 183464880.0000 - val_acc: 0.8981\n",
      "Epoch 10/25\n",
      "1373/1373 [==============================] - 216s 158ms/step - loss: 68279016.0000 - acc: 0.9249 - val_loss: 218100512.0000 - val_acc: 0.8937\n",
      "Epoch 11/25\n",
      "1373/1373 [==============================] - 217s 158ms/step - loss: 70427808.0000 - acc: 0.9274 - val_loss: 211183264.0000 - val_acc: 0.8931\n",
      "Epoch 12/25\n",
      " 298/1373 [=====>........................] - ETA: 2:32 - loss: 69556240.0000 - acc: 0.9317"
     ]
    }
   ],
   "source": [
    "# 25-50\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=25,\n",
    "    validation_data=validation_generator,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polyphonic-deputy",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_hist_to_excel('history_model_all_data_3ConvLayers_down_015_01_01_26to50')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "terminal-denver",
   "metadata": {},
   "source": [
    "### Using the 'Down' Version - (0.15 ; 0.15 ; 0.1; 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-michigan",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (2, 2), activation='relu', input_shape=(150, 150, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.15))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2) ))\n",
    "model.add(layers.Dropout(0.15))\n",
    "model.add(layers.Conv2D(128, (4, 4), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2) ))\n",
    "model.add(layers.Dropout(0.1))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dropout(0.4))\n",
    "model.add(layers.Dense (43, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amazing-pennsylvania",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "#compilation\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.RMSprop(lr=1e-4), metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peripheral-narrative",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=50,\n",
    "    validation_data=validation_generator,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-vatican",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_hist_to_excel('history_model_all_data_3ConvLayers_down_015_015_01_0.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitting-seller",
   "metadata": {},
   "source": [
    "### Using the 'Down' Version - (0.15 ; 0.15 ; 0.1; 0.3)  - LR = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocational-venue",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (2, 2), activation='relu', input_shape=(150, 150, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.15))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2) ))\n",
    "model.add(layers.Dropout(0.15))\n",
    "model.add(layers.Conv2D(128, (4, 4), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2) ))\n",
    "model.add(layers.Dropout(0.1))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense (43, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forced-empire",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "#compilation\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.RMSprop(lr=1e-5), metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "velvet-berry",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=100,\n",
    "    validation_data=validation_generator,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-howard",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_hist_to_excel('history_model_all_data_3ConvLayers_down_decrease_lr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ruled-programming",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displaying curves of loss and accuracy during training\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history[\"acc\"]\n",
    "val_acc = history.history[\"val_acc\"]\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, \"bo\", label=\"Training acc\")\n",
    "plt.plot(epochs, val_acc, \"b\", label=\"Validation acc\")\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "paperback-hughes",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
